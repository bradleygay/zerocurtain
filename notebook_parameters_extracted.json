{
  "splits": [
    {
      "cell": 23,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "# Soil Temperature Recall\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom matp"
    },
    {
      "cell": 106,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": "_idx = train_test_split(\n#         range(len(X)), test_size=0.2, \n#         stratify=X['spatial_group'], random_s"
    },
    {
      "cell": 106,
      "parameter": "test_size",
      "match": "test_size=0.25",
      "value": [
        "0.25"
      ],
      "context": "_idx = train_test_split(\n#         train_val_idx, test_size=0.25,  # 25% of 80% = 20% of total\n#         stratify="
    },
    {
      "cell": 106,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "ff test set first\n#     train_val_idx, test_idx = train_test_split(\n#         range(len(X)), test_size=0.2, \n#       "
    },
    {
      "cell": 106,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "# Then split train/val\n#     train_idx, val_idx = train_test_split(\n#         train_val_idx, test_size=0.25,  # 25% o"
    },
    {
      "cell": 106,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "# import os\n# import numpy as np\n# import pandas as pd\n# import gc\n# import pickle\n# import psutil\n# from datetime import datetime, timedelta\n# import time\n# from scipy.interpolate import interp1d\n# i"
    },
    {
      "cell": 107,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": "_idx = train_test_split(\n#         range(len(X)), test_size=0.2, \n#         stratify=X['spatial_group'], random_s"
    },
    {
      "cell": 107,
      "parameter": "test_size",
      "match": "test_size=0.25",
      "value": [
        "0.25"
      ],
      "context": "_idx = train_test_split(\n#         train_val_idx, test_size=0.25,  # 25% of 80% = 20% of total\n#         stratify="
    },
    {
      "cell": 107,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "ff test set first\n#     train_val_idx, test_idx = train_test_split(\n#         range(len(X)), test_size=0.2, \n#       "
    },
    {
      "cell": 107,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "# Then split train/val\n#     train_idx, val_idx = train_test_split(\n#         train_val_idx, test_size=0.25,  # 25% o"
    },
    {
      "cell": 107,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "# import os\n# import numpy as np\n# import pandas as pd\n# import gc\n# import pickle\n# import psutil\n# from datetime import datetime, timedelta\n# import time\n# from scipy.interpolate import interp1d\n# i"
    },
    {
      "cell": 195,
      "parameter": "test_size",
      "match": "test_size=0.3",
      "value": [
        "0.3"
      ],
      "context": " X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n#     X_val, X_test"
    },
    {
      "cell": 195,
      "parameter": "test_size",
      "match": "test_size=0.5",
      "value": [
        "0.5"
      ],
      "context": " y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n    \n#     # B"
    },
    {
      "cell": 195,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "ets...\")\n#     X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
    },
    {
      "cell": 195,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": " stratify=y)\n#     X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, st"
    },
    {
      "cell": 195,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "# import os\n# import tensorflow as tf\n\n# # Configure memory growth to avoid pre-allocating all GPU memory\n# physical_devices = tf.config.list_physical_devices('GPU')\n# if physical_devices:\n#     for d"
    },
    {
      "cell": 197,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "based split rather than random split\ndef temporal_train_test_split(X, y, metadata, val_ratio=0.2, test_ratio=0.1):\n  "
    },
    {
      "cell": 197,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "# data_loader.py\nimport os\nimport pandas as pd\nimport numpy as np\nimport pyarrow as pa\nimport pyarrow.feather as pf\nimport pyarrow.compute as pc\nimport pyarrow.dataset as ds\nimport gc\nfrom tqdm.auto i"
    },
    {
      "cell": 212,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "ssing import StandardScaler\n\n# def spatiotemporal_train_test_split(X, y, metadata, test_fraction=0.2, val_fraction=0."
    },
    {
      "cell": 212,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "# from tqdm import tqdm\n# import numpy as np\n# from sklearn.neighbors import KernelDensity\n# from sklearn.preprocessing import StandardScaler\n\n# def spatiotemporal_train_test_split(X, y, metadata, tes"
    },
    {
      "cell": 221,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "sed split rather than random split\n# def temporal_train_test_split(X, y, metadata, val_ratio=0.2, test_ratio=0.1):\n# "
    },
    {
      "cell": 221,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "ing import StandardScaler\n\n# # def spatiotemporal_train_test_split(X, y, metadata, test_fraction=0.2, val_fraction=0."
    },
    {
      "cell": 221,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "# #ALL OF THE CODE THROUGH THIS ITERATION OF SPLITTING\n# import cartopy.crs as ccrs\n# import cartopy.feature as cfeature\n# import cmocean\n# import gc\n# import glob\n# import json\n# import logging\n# imp"
    },
    {
      "cell": 227,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": "f stratified_spatiotemporal_split(X, y, metadata, test_size=0.2, val_size=0.15, \n                                "
    },
    {
      "cell": 230,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": "t(\n    X=X, \n    y=y, \n    metadata=metadata,\n    test_size=0.2, \n    val_size=0.15\n)"
    },
    {
      "cell": 236,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "based split rather than random split\ndef temporal_train_test_split(X, y, metadata, val_ratio=0.2, test_ratio=0.1):\n  "
    },
    {
      "cell": 236,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "import os\nimport numpy as np\nimport pandas as pd\nimport gc\nimport pickle\nimport psutil\nfrom datetime import datetime, timedelta\nimport time\nfrom scipy.interpolate import interp1d\n\ndef memory_usage():\n"
    },
    {
      "cell": 239,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": "d_spatiotemporal_split(\n#         X, y, metadata, test_size=0.2, val_size=0.15, checkpoint_dir=checkpoint_dir\n#  "
    },
    {
      "cell": 326,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "sed split rather than random split\n# def temporal_train_test_split(X, y, metadata, val_ratio=0.2, test_ratio=0.1):\n# "
    },
    {
      "cell": 326,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "# #DEBUGGING\n# import os,sys\n# import cartopy.crs as ccrs\n# import cartopy.feature as cfeature\n# import cmocean\n# import gc\n# import glob\n# import json\n# import logging\n# import matplotlib.gridspec as"
    },
    {
      "cell": 347,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": "d_spatiotemporal_split(\n#         X, y, metadata, test_size=0.2, val_size=0.15, checkpoint_dir=checkpoint_dir\n#  "
    },
    {
      "cell": 425,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": "f stratified_spatiotemporal_split(X, y, metadata, test_size=0.2, val_size=0.15, \n#                               "
    },
    {
      "cell": 425,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": " X=X, \n#     y=y, \n#     metadata=metadata,\n#     test_size=0.2, \n#     val_size=0.15\n# )\n\n# with open(\"zero_curt"
    },
    {
      "cell": 425,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": "d_spatiotemporal_split(\n#         X, y, metadata, test_size=0.2, val_size=0.15, checkpoint_dir=checkpoint_dir\n#  "
    },
    {
      "cell": 425,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "sed split rather than random split\n# def temporal_train_test_split(X, y, metadata, val_ratio=0.2, test_ratio=0.1):\n# "
    },
    {
      "cell": 425,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "# # ALL CODE FOR DEBUGGING\n\n# # data_loader.py\n# import os\n# import pandas as pd\n# import numpy as np\n# import pyarrow as pa\n# import pyarrow.feather as pf\n# import pyarrow.compute as pc\n# import pyar"
    },
    {
      "cell": 453,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": "f stratified_spatiotemporal_split(X, y, metadata, test_size=0.2, val_size=0.15, \n#                               "
    },
    {
      "cell": 453,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": " X=X, \n#     y=y, \n#     metadata=metadata,\n#     test_size=0.2, \n#     val_size=0.15\n# )\n\n# with open(\"zero_curt"
    },
    {
      "cell": 453,
      "parameter": "test_size",
      "match": "test_size=0.2",
      "value": [
        "0.2"
      ],
      "context": "d_spatiotemporal_split(\n#         X, y, metadata, test_size=0.2, val_size=0.15, checkpoint_dir=checkpoint_dir\n#  "
    },
    {
      "cell": 585,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "in, y_val, y_test, train_weights = spatiotemporal_train_test_split(\n    X, y, metadata, test_fraction=0.2, val_fracti"
    },
    {
      "cell": 585,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "X_train, X_val, X_test, y_train, y_val, y_test, train_weights = spatiotemporal_train_test_split(\n    X, y, metadata, test_fraction=0.2, val_fraction=0.15\n)"
    },
    {
      "cell": 630,
      "parameter": "test_size",
      "match": "test_size=0.1",
      "value": [
        "0.1"
      ],
      "context": "        np.arange(total_samples),\n                test_size=0.1,\n                random_state=42,\n               "
    },
    {
      "cell": 630,
      "parameter": "test_size",
      "match": "test_size=0.11",
      "value": [
        "0.11"
      ],
      "context": "               train_val_indices,\n                test_size=0.11,  # ~10% of original data\n                random_"
    },
    {
      "cell": 630,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "set\n            train_val_indices, test_indices = train_test_split(\n                np.arange(total_samples),\n       "
    },
    {
      "cell": 630,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "rain/val\n            train_indices, val_indices = train_test_split(\n                train_val_indices,\n              "
    },
    {
      "cell": 630,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nZero Curtain Model - Improved Implementation\n\nA comprehensive model for zero curtain detection in permafrost monitoring,\nwith specific optimizations "
    },
    {
      "cell": 646,
      "parameter": "train_test_split",
      "match": "train_test_split(",
      "value": null,
      "context": "based split rather than random split\ndef temporal_train_test_split(X, y, metadata, val_ratio=0.2, test_ratio=0.1):\n  "
    },
    {
      "cell": 646,
      "parameter": "split_operation",
      "match": "Found split operation",
      "context": "import os\nimport pandas as pd\nimport numpy as np\nimport pyarrow as pa\nimport pyarrow.feather as pf\nimport pyarrow.compute as pc\nimport pyarrow.dataset as ds\nimport gc\nfrom tqdm.auto import tqdm\n\ndef g"
    },
    {
      "cell": 725,
      "parameter": "train_split",
      "match": "training(self, windowed_data, val_split=0.2",
      "value": [
        "training(self, windowed_data, val_split",
        "0.2"
      ],
      "context": "  return windowed_data\n    \n#     def prepare_for_training(self, windowed_data, val_split=0.2):\n#         \"\"\"Prepare data for model training\"\"\""
    },
    {
      "cell": 726,
      "parameter": "train_split",
      "match": "training_batches(processed_data, batch_size=32, val_split=0.2",
      "value": [
        "training_batches(processed_data, batch_size=32, val_split",
        "0.2"
      ],
      "context": "]\n    \n#     return processed_data\n\n# def prepare_training_batches(processed_data, batch_size=32, val_split=0.2):\n#     \"\"\"Prepare data batches for training with"
    }
  ],
  "sampling": [
    {
      "cell": 173,
      "parameter": "frac_sample",
      "match": ".sample(frac=0.001",
      "value": [
        "0.001"
      ],
      "context": "sample_df = merged_df.sample(frac=0.001)\n\nsample_results = run_full_analysis_pipeline_wit"
    }
  ],
  "sequence_params": [
    {
      "cell": 195,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "ata_for_deep_learning(merged_df, enhanced_events, sequence_length=6):\n#     \"\"\"\n#     Prepare time series data for de"
    },
    {
      "cell": 195,
      "parameter": "sequence_length",
      "match": "sequence_length = 24",
      "value": [
        "24"
      ],
      "context": "    # Prepare sequences with sliding window\n#     sequence_length = 24  # 24 time steps - adjust based on your data freq"
    },
    {
      "cell": 195,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "\n\n\n# def apply_model_to_new_data(model, new_data, sequence_length=6):\n#     \"\"\"\n#     Apply a trained model to detect"
    },
    {
      "cell": 195,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "                 merged_df,\n#                     sequence_length=24\n#                 )\n                \n#           "
    },
    {
      "cell": 195,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "  batch_df,\n#                                     sequence_length=24\n#                                 )\n             "
    },
    {
      "cell": 197,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "eep_learning_efficiently(feather_path, events_df, sequence_length=6, \n                                               "
    },
    {
      "cell": 197,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "vents_df=enhanced_events,\n                        sequence_length=24,  # Use 24 time steps as in your original code\n  "
    },
    {
      "cell": 197,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "eather_path=feather_path,\n                        sequence_length=24,\n                        output_dir=pred_dir,\n   "
    },
    {
      "cell": 197,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "odel_to_new_data_efficiently(model, feather_path, sequence_length=6, \n                                        output_"
    },
    {
      "cell": 197,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "   events_df=enhanced_events,\n                    sequence_length=24,\n                    output_dir=os.path.join(outp"
    },
    {
      "cell": 197,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "   feather_path=feather_path,\n                    sequence_length=24,\n                    output_dir=os.path.join(outp"
    },
    {
      "cell": 208,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "arse_dates=['datetime_min', 'datetime_max']),\n    sequence_length=6,\n    output_dir='zero_curtain_pipeline/modeling/m"
    },
    {
      "cell": 209,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "ressed.feather',\n#     events_df=events_df,\n#     sequence_length=6,\n#     output_dir=output_dir,\n#     batch_size=ba"
    },
    {
      "cell": 221,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "eep_learning_efficiently(feather_path, events_df, sequence_length=6, \n#                                              "
    },
    {
      "cell": 221,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "nts_df=enhanced_events,\n#                         sequence_length=24,  # Use 24 time steps as in your original code\n# "
    },
    {
      "cell": 221,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "ther_path=feather_path,\n#                         sequence_length=24,\n#                         output_dir=pred_dir,\n#"
    },
    {
      "cell": 221,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "odel_to_new_data_efficiently(model, feather_path, sequence_length=6, \n#                                         outpu"
    },
    {
      "cell": 221,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": " events_df=enhanced_events,\n#                     sequence_length=24,\n#                     output_dir=os.path.join(ou"
    },
    {
      "cell": 221,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": " feather_path=feather_path,\n#                     sequence_length=24,\n#                     output_dir=os.path.join(ou"
    },
    {
      "cell": 221,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "ressed.feather',\n#     events_df=events_df,\n#     sequence_length=6,\n#     output_dir='zero_curtain_pipeline/modeling"
    },
    {
      "cell": 236,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "eep_learning_efficiently(feather_path, events_df, sequence_length=6, \n                                               "
    },
    {
      "cell": 236,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "vents_df=enhanced_events,\n                        sequence_length=24,  # Use 24 time steps as in your original code\n  "
    },
    {
      "cell": 236,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "eather_path=feather_path,\n                        sequence_length=24,\n                        output_dir=pred_dir,\n   "
    },
    {
      "cell": 236,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "odel_to_new_data_efficiently(model, feather_path, sequence_length=6, \n                                        output_"
    },
    {
      "cell": 236,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "   events_df=enhanced_events,\n                    sequence_length=24,\n                    output_dir=os.path.join(outp"
    },
    {
      "cell": 236,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "   feather_path=feather_path,\n                    sequence_length=24,\n                    output_dir=os.path.join(outp"
    },
    {
      "cell": 326,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "eep_learning_efficiently(feather_path, events_df, sequence_length=6, \n#                                              "
    },
    {
      "cell": 326,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "nts_df=enhanced_events,\n#                         sequence_length=24,  # Use 24 time steps as in your original code\n# "
    },
    {
      "cell": 326,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "ther_path=feather_path,\n#                         sequence_length=24,\n#                         output_dir=pred_dir,\n#"
    },
    {
      "cell": 326,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "odel_to_new_data_efficiently(model, feather_path, sequence_length=6, \n#                                         outpu"
    },
    {
      "cell": 326,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": " events_df=enhanced_events,\n#                     sequence_length=24,\n#                     output_dir=os.path.join(ou"
    },
    {
      "cell": 326,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": " feather_path=feather_path,\n#                     sequence_length=24,\n#                     output_dir=os.path.join(ou"
    },
    {
      "cell": 425,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "eep_learning_efficiently(feather_path, events_df, sequence_length=6, \n#                                              "
    },
    {
      "cell": 425,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "nts_df=enhanced_events,\n#                         sequence_length=24,  # Use 24 time steps as in your original code\n# "
    },
    {
      "cell": 425,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "ther_path=feather_path,\n#                         sequence_length=24,\n#                         output_dir=pred_dir,\n#"
    },
    {
      "cell": 425,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "odel_to_new_data_efficiently(model, feather_path, sequence_length=6, \n#                                         outpu"
    },
    {
      "cell": 425,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": " events_df=enhanced_events,\n#                     sequence_length=24,\n#                     output_dir=os.path.join(ou"
    },
    {
      "cell": 425,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": " feather_path=feather_path,\n#                     sequence_length=24,\n#                     output_dir=os.path.join(ou"
    },
    {
      "cell": 425,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "se_dates=['datetime_min', 'datetime_max']),\n#     sequence_length=6,\n#     output_dir='zero_curtain_pipeline/modeling"
    },
    {
      "cell": 646,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "eep_learning_efficiently(feather_path, events_df, sequence_length=6, \n                                               "
    },
    {
      "cell": 646,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "vents_df=enhanced_events,\n                        sequence_length=24,  # Use 24 time steps as in your original code\n  "
    },
    {
      "cell": 646,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "eather_path=feather_path,\n                        sequence_length=24,\n                        output_dir=pred_dir,\n   "
    },
    {
      "cell": 646,
      "parameter": "sequence_length",
      "match": "sequence_length=6",
      "value": [
        "6"
      ],
      "context": "odel_to_new_data_efficiently(model, feather_path, sequence_length=6, \n                                        output_"
    },
    {
      "cell": 646,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "   events_df=enhanced_events,\n                    sequence_length=24,\n                    output_dir=os.path.join(outp"
    },
    {
      "cell": 646,
      "parameter": "sequence_length",
      "match": "sequence_length=24",
      "value": [
        "24"
      ],
      "context": "   feather_path=feather_path,\n                    sequence_length=24,\n                    output_dir=os.path.join(outp"
    }
  ],
  "validation_params": [],
  "test_params": [],
  "numeric_constants": [
    {
      "cell": 2,
      "variable": "fontsize",
      "value": "14",
      "context": "8)\n    cbar.set_label(column, fontsize=14)\n    if title:\n        plt.ti"
    },
    {
      "cell": 2,
      "variable": "fontsize",
      "value": "16",
      "context": "tle:\n        plt.title(title, fontsize=16)\n    if output_path:\n        "
    },
    {
      "cell": 3,
      "variable": "size",
      "value": "1920",
      "context": "ble-dev-shm-usage', '--window-size=1920,1080', \n                    '"
    },
    {
      "cell": 11,
      "variable": "chunk_size",
      "value": "1000000",
      "context": "ed_df) > 1000000:\n            chunk_size = 1000000\n            for i, chunk_df i"
    },
    {
      "cell": 11,
      "variable": "chunk_size",
      "value": "1000000",
      "context": "_zone'].fillna('unknown')\n    chunk_size = 1000000\n    for i in range(0, len(df)"
    },
    {
      "cell": 20,
      "variable": "size",
      "value": "12",
      "context": "   cbar.set_label(cbar_label, size=12, labelpad=10)\n    \n    # Add "
    },
    {
      "cell": 20,
      "variable": "size",
      "value": "16",
      "context": "p_ax.set_title(title, pad=25, size=16)\n    \n    return fig\n\n# Creat"
    },
    {
      "cell": 20,
      "variable": "size",
      "value": "12",
      "context": "   cbar.set_label(cbar_label, size=12)\n    \n#     # Add measurement"
    },
    {
      "cell": 20,
      "variable": "fontsize",
      "value": "8",
      "context": "      transform=ax.transAxes, fontsize=8, verticalalignment='top')\n   "
    },
    {
      "cell": 20,
      "variable": "size",
      "value": "16",
      "context": "  ax.set_title(title, pad=25, size=16)\n\n#     #print(f\"Value range:"
    },
    {
      "cell": 21,
      "variable": "size",
      "value": "12",
      "context": "   cbar.set_label(cbar_label, size=12, labelpad=10)\n    \n    # Add "
    },
    {
      "cell": 21,
      "variable": "size",
      "value": "16",
      "context": "p_ax.set_title(title, pad=25, size=16)\n    \n    return fig\n\ndef cre"
    },
    {
      "cell": 21,
      "variable": "size",
      "value": "12",
      "context": "   cbar.set_label(cbar_label, size=12)#, labelpad=0.15)\n\n#     ax.s"
    },
    {
      "cell": 21,
      "variable": "size",
      "value": "16",
      "context": "  ax.set_title(title, pad=25, size=16)\n    \n#     return fig\n\n# fig"
    },
    {
      "cell": 22,
      "variable": "size",
      "value": "12",
      "context": "   cbar.set_label(cbar_label, size=12, labelpad=10)\n    \n    # Add "
    },
    {
      "cell": 22,
      "variable": "size",
      "value": "16",
      "context": "p_ax.set_title(title, pad=25, size=16)\n    \n    return fig\n\ndef cre"
    },
    {
      "cell": 23,
      "variable": "chunk_size",
      "value": "100000",
      "context": "elf, input_file, output_file, chunk_size=100000):\n        self.logger.info(f\""
    },
    {
      "cell": 23,
      "variable": "chunk_size",
      "value": "100000",
      "context": "elf, input_file, output_file, chunk_size=100000):\n        self.logger.info(f\""
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "10",
      "context": "bel('Mean\\nTemperature (\u00b0C)', fontsize=10, labelpad=10)\n    cbar.ax.tic"
    },
    {
      "cell": 23,
      "variable": "labelsize",
      "value": "9",
      "context": "d=10)\n    cbar.ax.tick_params(labelsize=9)\n    ymax = site_data['durati"
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "10",
      "context": "  ax1.set_xlabel('Depth (m)', fontsize=10)\n    ax1.set_ylabel('Duration"
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "10",
      "context": "set_ylabel('Duration (days)', fontsize=10)\n    site_lat = site_data.lat"
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "11",
      "context": ")',\n                  pad=15, fontsize=11)\n    ax1.legend(handles=leg_e"
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "9",
      "context": "='center left',\n              fontsize=9,\n              title_fontsize"
    },
    {
      "cell": 23,
      "variable": "title_fontsize",
      "value": "10",
      "context": "    fontsize=9,\n              title_fontsize=10)\n    ax2 = fig.add_subplot(gs"
    },
    {
      "cell": 23,
      "variable": "markersize",
      "value": "5",
      "context": "' ').title(),\n                markersize=5, linewidth=1.5)\n    y_vals = "
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "10",
      "context": "1)\n    ax2.set_xlabel('Year', fontsize=10)\n    ax2.set_ylabel('Mean Dur"
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "10",
      "context": "label('Mean Duration (days)', fontsize=10)\n    ax2.set_title('Duration "
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "11",
      "context": "Year and Depth Zone', pad=15, fontsize=11)\n    ax2.legend(title='Depth "
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "9",
      "context": "           loc='center left', fontsize=9, title_fontsize=10)\n    ax3 ="
    },
    {
      "cell": 23,
      "variable": "title_fontsize",
      "value": "10",
      "context": "oc='center left', fontsize=9, title_fontsize=10)\n    ax3 = fig.add_subplot(gs"
    },
    {
      "cell": 23,
      "variable": "markersize",
      "value": "4",
      "context": "  flierprops=dict(marker='o', markersize=4, alpha=0.5))\n    temp_min = s"
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "10",
      "context": " ax3.set_xlabel('Depth Zone', fontsize=10)\n    ax3.set_ylabel('Temperat"
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "10",
      "context": "et_ylabel('Temperature (\u00b0C)', fontsize=10)\n    ax3.set_title('Temperatu"
    },
    {
      "cell": 23,
      "variable": "fontsize",
      "value": "11",
      "context": "ution by Depth Zone', pad=15, fontsize=11)\n    for ax in [ax1, ax2, ax3"
    },
    {
      "cell": 23,
      "variable": "labelsize",
      "value": "9",
      "context": "a=0.6)\n        ax.tick_params(labelsize=9)\n    plt.subplots_adjust(righ"
    },
    {
      "cell": 31,
      "variable": "chunk_size",
      "value": "1000000",
      "context": ": Process in chunks\n#         chunk_size = 1000000\n#         unique_combos = set"
    },
    {
      "cell": 33,
      "variable": "site_batch_size",
      "value": "20",
      "context": "                              site_batch_size=20, checkpoint_interval=5, \n#   "
    },
    {
      "cell": 43,
      "variable": "fontsize",
      "value": "10",
      "context": "nt, ha='center', va='center', fontsize=10, fontweight='bold')\n    \n    "
    },
    {
      "cell": 43,
      "variable": "head_length",
      "value": "0.02",
      "context": "0.12, -0.05, head_width=0.02, head_length=0.02, fc='black', ec='black')\n    "
    },
    {
      "cell": 43,
      "variable": "head_length",
      "value": "0.02",
      "context": "0.12, -0.05, head_width=0.02, head_length=0.02, fc='black', ec='black')\n    "
    },
    {
      "cell": 43,
      "variable": "head_length",
      "value": "0.02",
      "context": "7, 0, -0.05, head_width=0.02, head_length=0.02, fc='black', ec='black')\n    "
    },
    {
      "cell": 43,
      "variable": "head_length",
      "value": "0.02",
      "context": "5, 0, -0.05, head_width=0.02, head_length=0.02, fc='black', ec='black')\n    "
    },
    {
      "cell": 43,
      "variable": "head_length",
      "value": "0.02",
      "context": "7, 0, -0.05, head_width=0.02, head_length=0.02, fc='black', ec='black')\n    "
    },
    {
      "cell": 43,
      "variable": "head_length",
      "value": "0.02",
      "context": "0.12, -0.05, head_width=0.02, head_length=0.02, fc='black', ec='black')\n    "
    },
    {
      "cell": 43,
      "variable": "head_length",
      "value": "0.02",
      "context": "-0.12, -0.2, head_width=0.02, head_length=0.02, fc='black', ec='black')\n    "
    },
    {
      "cell": 43,
      "variable": "head_length",
      "value": "0.02",
      "context": "5, 0, -0.05, head_width=0.02, head_length=0.02, fc='black', ec='black')\n    "
    },
    {
      "cell": 43,
      "variable": "head_length",
      "value": "0.02",
      "context": "1, 0, -0.02, head_width=0.02, head_length=0.02, fc='black', ec='black')\n    "
    },
    {
      "cell": 43,
      "variable": "fontsize",
      "value": "14",
      "context": " Curtain Model Architecture\", fontsize=14, fontweight='bold')\n    plt.t"
    },
    {
      "cell": 43,
      "variable": "fontsize",
      "value": "10",
      "context": ": 48,525 (47,527 trainable)\", fontsize=10)\n    \n    # Remove axes\n    p"
    },
    {
      "cell": 45,
      "variable": "fontsize",
      "value": "12",
      "context": "nt, ha='center', va='center', fontsize=12, fontweight='bold')\n        \n"
    },
    {
      "cell": 45,
      "variable": "fontsize",
      "value": "8",
      "context": "er, ha='center', va='center', fontsize=8)\n    \n    # Draw connections "
    },
    {
      "cell": 45,
      "variable": "head_length",
      "value": "0.01",
      "context": "             head_width=0.01, head_length=0.01, fc='black', ec='black')\n    "
    },
    {
      "cell": 45,
      "variable": "head_length",
      "value": "0.01",
      "context": "             head_width=0.01, head_length=0.01, fc='black', ec='black')\n    "
    },
    {
      "cell": 45,
      "variable": "head_length",
      "value": "0.01",
      "context": "             head_width=0.01, head_length=0.01, fc='black', ec='black')\n    "
    },
    {
      "cell": 45,
      "variable": "head_length",
      "value": "0.01",
      "context": "             head_width=0.01, head_length=0.01, fc='black', ec='black')\n    "
    },
    {
      "cell": 45,
      "variable": "fontsize",
      "value": "14",
      "context": "\", \n             ha='center', fontsize=14, fontweight='bold')\n    \n    "
    },
    {
      "cell": 45,
      "variable": "fontsize",
      "value": "9",
      "context": ".text(0.05, 0.05, param_text, fontsize=9, va='bottom')\n    \n    # Remo"
    },
    {
      "cell": 45,
      "variable": "fontsize",
      "value": "9",
      "context": "me, ha='center', va='center', fontsize=9, fontweight='bold')\n    \n    "
    },
    {
      "cell": 45,
      "variable": "head_length",
      "value": "0.01",
      "context": "             head_width=0.01, head_length=0.01, fc='black', ec='black', \n   "
    },
    {
      "cell": 45,
      "variable": "fontsize",
      "value": "14",
      "context": "\", \n             ha='center', fontsize=14, fontweight='bold')\n    \n    "
    },
    {
      "cell": 45,
      "variable": "fontsize",
      "value": "9",
      "context": ".text(0.02, -0.15, info_text, fontsize=9, va='top')\n    \n    # Remove "
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "9",
      "context": "'], ha='center', va='center', fontsize=9, fontweight='bold')\n    \n    "
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "14",
      "context": " Architecture\", \n             fontsize=14, fontweight='bold', ha='cente"
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "9",
      "context": ".text(0.5, -0.02, param_info, fontsize=9, ha='center', transform=ax.tr"
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "8",
      "context": "(0.5, -0.06, components_info, fontsize=8, ha='center', transform=ax.tr"
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "10",
      "context": "'], ha='center', va='center', fontsize=10, fontweight='bold')\n    \n    "
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "14",
      "context": " Architecture\", \n             fontsize=14, fontweight='bold', ha='cente"
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "8",
      "context": "t.text(0.02, 0.02, info_text, fontsize=8, va='bottom', transform=ax.tr"
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "9",
      "context": "%)\",\n            va='center', fontsize=9\n        )\n    \n    # Customiz"
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "14",
      "context": "el - Parameter Distribution', fontsize=14, fontweight='bold')\n    ax.se"
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "10",
      "context": "label('Number of Parameters', fontsize=10)\n    ax.spines['top'].set_vis"
    },
    {
      "cell": 47,
      "variable": "labelsize",
      "value": "10",
      "context": "\n    ax.tick_params(axis='y', labelsize=10)\n    \n    # Add total paramet"
    },
    {
      "cell": 47,
      "variable": "fontsize",
      "value": "10",
      "context": "orm=ax.transAxes, ha='right', fontsize=10, fontweight='bold'\n    )\n    "
    },
    {
      "cell": 48,
      "variable": "fontsize",
      "value": "9",
      "context": "'], ha='center', va='center', fontsize=9, fontweight='bold')\n    \n    "
    },
    {
      "cell": 48,
      "variable": "fontsize",
      "value": "14",
      "context": "ta Flow Chart\", \n             fontsize=14, fontweight='bold', ha='cente"
    },
    {
      "cell": 48,
      "variable": "fontsize",
      "value": "8",
      "context": "t.text(0.5, 0.03, annotation, fontsize=8, ha='center', transform=ax.tr"
    },
    {
      "cell": 49,
      "variable": "fontsize",
      "value": "7",
      "context": "    ha='center', va='bottom', fontsize=7, rotation=90)\n        else:\n "
    },
    {
      "cell": 49,
      "variable": "fontsize",
      "value": "7",
      "context": "    ha='center', va='bottom', fontsize=7)\n    \n    # Add layer names\n "
    },
    {
      "cell": 49,
      "variable": "fontsize",
      "value": "8",
      "context": "ayer in layers], rotation=90, fontsize=8)\n    \n    # Customize plot\n  "
    },
    {
      "cell": 49,
      "variable": "fontsize",
      "value": "10",
      "context": "ber of Elements (log scale)', fontsize=10)\n    ax.set_title('Zero Curta"
    },
    {
      "cell": 49,
      "variable": "fontsize",
      "value": "14",
      "context": "in Model - Layer Dimensions', fontsize=14, fontweight='bold')\n    \n    "
    },
    {
      "cell": 49,
      "variable": "fontsize",
      "value": "8",
      "context": "           loc='upper right', fontsize=8, ncol=3)\n    \n    # Add annot"
    },
    {
      "cell": 49,
      "variable": "fontsize",
      "value": "8",
      "context": " \n               ha=\"center\", fontsize=8)\n    \n    plt.tight_layout()\n"
    },
    {
      "cell": 102,
      "variable": "length",
      "value": "27304593",
      "context": "708667],\n      dtype='int64', length=27304593)"
    },
    {
      "cell": 105,
      "variable": "site_batch_size",
      "value": "10",
      "context": "{events_dir}',\")\n# print(\"    site_batch_size=10,\")\n# print(\"    checkpoint_in"
    },
    {
      "cell": 106,
      "variable": "chunk_size",
      "value": "1000000",
      "context": ": Process in chunks\n#         chunk_size = 1000000\n#         unique_combos = set"
    },
    {
      "cell": 106,
      "variable": "test_size",
      "value": "0.2",
      "context": "lit(\n#         range(len(X)), test_size=0.2, \n#         stratify=X['spati"
    },
    {
      "cell": 106,
      "variable": "test_size",
      "value": "0.25",
      "context": "lit(\n#         train_val_idx, test_size=0.25,  # 25% of 80% = 20% of total"
    },
    {
      "cell": 106,
      "variable": "site_batch_size",
      "value": "10",
      "context": "                              site_batch_size=10, checkpoint_interval=5, \n#   "
    },
    {
      "cell": 106,
      "variable": "site_batch_size",
      "value": "10",
      "context": "                              site_batch_size=10, checkpoint_interval=5, \n#   "
    },
    {
      "cell": 106,
      "variable": "site_batch_size",
      "value": "10",
      "context": "     max_gap_hours=8,\n# #     site_batch_size=10,\n# #     verbose=False  # We "
    },
    {
      "cell": 106,
      "variable": "site_batch_size",
      "value": "10",
      "context": "\n#     max_gap_hours=8,\n#     site_batch_size=10,\n#     verbose=False\n# ):\n#  "
    },
    {
      "cell": 106,
      "variable": "site_batch_size",
      "value": "10",
      "context": "imized batch processing\n#     site_batch_size = 10\n#     max_gap_hours = 8\n#    "
    },
    {
      "cell": 106,
      "variable": "site_batch_size",
      "value": "10",
      "context": "e-based parameter\n# #         site_batch_size=10,        # Smaller batch size "
    },
    {
      "cell": 107,
      "variable": "chunk_size",
      "value": "1000000",
      "context": ": Process in chunks\n#         chunk_size = 1000000\n#         unique_combos = set"
    },
    {
      "cell": 107,
      "variable": "test_size",
      "value": "0.2",
      "context": "lit(\n#         range(len(X)), test_size=0.2, \n#         stratify=X['spati"
    },
    {
      "cell": 107,
      "variable": "test_size",
      "value": "0.25",
      "context": "lit(\n#         train_val_idx, test_size=0.25,  # 25% of 80% = 20% of total"
    },
    {
      "cell": 107,
      "variable": "site_batch_size",
      "value": "10",
      "context": "                              site_batch_size=10, checkpoint_interval=5, \n#   "
    },
    {
      "cell": 107,
      "variable": "site_batch_size",
      "value": "10",
      "context": "                              site_batch_size=10, checkpoint_interval=5,\n#    "
    },
    {
      "cell": 107,
      "variable": "chunk_size",
      "value": "500000",
      "context": "d memory issues\n#             chunk_size = 500000\n#             moisture_capabl"
    },
    {
      "cell": 107,
      "variable": "chunk_size",
      "value": "500000",
      "context": "extraction...\")\n#             chunk_size = 500000\n#             all_combination"
    },
    {
      "cell": 107,
      "variable": "chunk_size",
      "value": "100000",
      "context": "ta loading...\")\n#             chunk_size = 100000\n#             filtered_chunks"
    },
    {
      "cell": 107,
      "variable": "site_batch_size",
      "value": "10",
      "context": "                              site_batch_size=10, checkpoint_interval=5,\n#    "
    },
    {
      "cell": 108,
      "variable": "super_batch_size",
      "value": "200",
      "context": "                              super_batch_size=200, max_workers=None,\n          "
    },
    {
      "cell": 108,
      "variable": "worker_batch_size",
      "value": "1",
      "context": "orker_batch_size < 1:\n        worker_batch_size = 1\n    super_batch_size = worker"
    },
    {
      "cell": 108,
      "variable": "super_batch_size",
      "value": "200",
      "context": "                              super_batch_size=200, max_workers=None,\n          "
    },
    {
      "cell": 108,
      "variable": "worker_batch_size",
      "value": "1",
      "context": "orker_batch_size < 1:\n        worker_batch_size = 1\n    super_batch_size = worker"
    },
    {
      "cell": 108,
      "variable": "super_batch_size",
      "value": "100",
      "context": "ain_moisture_run/events',\n    super_batch_size=100,  # Process 100 sites at a ti"
    },
    {
      "cell": 108,
      "variable": "super_batch_size",
      "value": "500",
      "context": "ain_moisture_run/events',\n    super_batch_size=500,\n    max_workers=None  # Auto"
    },
    {
      "cell": 108,
      "variable": "super_batch_size",
      "value": "50",
      "context": "uper_batch_size == 0:\n        super_batch_size = 50\n    \n    return {\n        'ma"
    },
    {
      "cell": 109,
      "variable": "site_batch_size",
      "value": "10",
      "context": "n_moisture_run/events',\n#     site_batch_size=10,\n#     checkpoint_interval=5,"
    },
    {
      "cell": 110,
      "variable": "site_batch_size",
      "value": "10",
      "context": "n_moisture_run/events',\n#     site_batch_size=10,\n#     checkpoint_interval=5,"
    },
    {
      "cell": 111,
      "variable": "site_batch_size",
      "value": "10",
      "context": "n_moisture_run/events',\n#     site_batch_size=10,\n#     checkpoint_interval=5\n"
    },
    {
      "cell": 145,
      "variable": "fontsize",
      "value": "9",
      "context": "ignment='bottom',\n            fontsize=9,\n            bbox=dict(faceco"
    },
    {
      "cell": 145,
      "variable": "fontsize",
      "value": "12",
      "context": "e('Zero Curtain Event Count', fontsize=12)\n    \n    # Plot 2: Mean dura"
    },
    {
      "cell": 145,
      "variable": "fontsize",
      "value": "12",
      "context": "'Mean Zero Curtain Duration', fontsize=12)\n    \n    # Add comprehensive"
    },
    {
      "cell": 145,
      "variable": "fontsize",
      "value": "14",
      "context": "p10:.1f}-{p90:.1f}h',\n        fontsize=14\n    )\n    \n    plt.tight_layo"
    },
    {
      "cell": 148,
      "variable": "fontsize",
      "value": "9",
      "context": "icks(rotation=45, ha='right', fontsize=9)\nplt.title('Zero-Curtain Even"
    },
    {
      "cell": 148,
      "variable": "fontsize",
      "value": "12",
      "context": "ear and Depth Zone',pad=10.0, fontsize=12);\nplt.xlabel('Year',labelpad="
    },
    {
      "cell": 149,
      "variable": "fontsize",
      "value": "9",
      "context": "icks(rotation=45, ha='right', fontsize=9)\nplt.title('Zero-Curtain Dura"
    },
    {
      "cell": 149,
      "variable": "fontsize",
      "value": "12",
      "context": "Duration by Season',pad=10.0, fontsize=12);\nplt.xlabel('Season',labelpa"
    },
    {
      "cell": 150,
      "variable": "fontsize",
      "value": "9",
      "context": "icks(rotation=45, ha='right', fontsize=9)\nplt.title('Mean Soil Tempera"
    },
    {
      "cell": 150,
      "variable": "fontsize",
      "value": "12",
      "context": "erature by Season', pad=10.0, fontsize=12);\nplt.xlabel('Season',labelpa"
    },
    {
      "cell": 151,
      "variable": "fontsize",
      "value": "9",
      "context": "icks(rotation=45, ha='right', fontsize=9)\nplt.title('Zero Curtain Dura"
    },
    {
      "cell": 151,
      "variable": "fontsize",
      "value": "12",
      "context": "ion by Depth Zone', pad=10.0, fontsize=12);\nplt.xlabel('Soil Temperatur"
    },
    {
      "cell": 152,
      "variable": "fontsize",
      "value": "9",
      "context": "icks(rotation=45, ha='right', fontsize=9)\nplt.title('Temperature vs Ze"
    },
    {
      "cell": 152,
      "variable": "fontsize",
      "value": "12",
      "context": " Curtain Duration', pad=10.0, fontsize=12);\nplt.xlabel('Mean Soil Tempe"
    },
    {
      "cell": 156,
      "variable": "fontsize",
      "value": "9",
      "context": "icks(rotation=45, ha='right', fontsize=9)\nplt.title('Zero-Curtain Even"
    },
    {
      "cell": 156,
      "variable": "fontsize",
      "value": "12",
      "context": "ear and Depth Zone',pad=10.0, fontsize=12);\nplt.xlabel('Year',labelpad="
    },
    {
      "cell": 158,
      "variable": "fontsize",
      "value": "9",
      "context": "icks(rotation=45, ha='right', fontsize=9)\nplt.title('Zero-Curtain Even"
    },
    {
      "cell": 158,
      "variable": "fontsize",
      "value": "12",
      "context": "Duration by Season',pad=10.0, fontsize=12);\nplt.xlabel('Season',labelpa"
    },
    {
      "cell": 160,
      "variable": "fontsize",
      "value": "9",
      "context": "icks(rotation=45, ha='right', fontsize=9)\nplt.title('Monthly Distribut"
    },
    {
      "cell": 162,
      "variable": "fontsize",
      "value": "14",
      "context": "y Year and Depth Zone',pad=10,fontsize=14)\nplt.tick_params(axis='y', la"
    },
    {
      "cell": 162,
      "variable": "labelsize",
      "value": "9",
      "context": "14)\nplt.tick_params(axis='y', labelsize=9)\nplt.legend();\nplt.tight_layo"
    },
    {
      "cell": 169,
      "variable": "fliersize",
      "value": "0",
      "context": "#          order=depth_order, fliersize=0, width=0.3, color='lightgray'"
    },
    {
      "cell": 169,
      "variable": "size",
      "value": "4",
      "context": "rder=depth_order, jitter=0.3, size=4)\n\nplt.axhline(y=events_depth["
    },
    {
      "cell": 169,
      "variable": "fontsize",
      "value": "9",
      "context": "4, frameon=True, shadow=True, fontsize=9)\n\nq75 = events_depth['duratio"
    },
    {
      "cell": 170,
      "variable": "labelsize",
      "value": "9",
      "context": "s[1, 0].tick_params(axis='y', labelsize=9)\n    \n#     # Keep the heatma"
    },
    {
      "cell": 170,
      "variable": "horizontal_spacing",
      "value": "0.1",
      "context": "rtical_spacing=0.1,\n#         horizontal_spacing=0.1\n#     )\n    \n#     # 5.2 3D s"
    },
    {
      "cell": 170,
      "variable": "size",
      "value": "5",
      "context": "arker=dict(\n#                 size=5,\n#                 color=even"
    },
    {
      "cell": 170,
      "variable": "size",
      "value": "8",
      "context": "                  marker=dict(size=8)\n#                 ),\n#      "
    },
    {
      "cell": 173,
      "variable": "frac",
      "value": "0.001",
      "context": "sample_df = merged_df.sample(frac=0.001)\n\nsample_results = run_full_a"
    },
    {
      "cell": 173,
      "variable": "batch_size",
      "value": "50",
      "context": "    use_checkpoints=True,\n    batch_size=50\n)\n\nimport matplotlib.pyplot a"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "el('Mean Duration (hours)')#, size=12, labelpad=10)\n    #cbar.ax.ti"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "=10)\n    #cbar.ax.tick_params(labelsize=10)\n    \n    plt.title('Mean Zer"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": " Curtain Duration by Site')#, size=14, pad=20)\n    \n    plt.tight_l"
    },
    {
      "cell": 173,
      "variable": "title_fontsize",
      "value": "12",
      "context": "le='Depth Zone',\n             title_fontsize=12,\n             fontsize=10,\n  "
    },
    {
      "cell": 173,
      "variable": "fontsize",
      "value": "10",
      "context": "tle_fontsize=12,\n             fontsize=10,\n             bbox_to_anchor="
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": "istribution by Depth Zone')#, size=14, pad=20)\n    \n    plt.tight_l"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "t_label('Duration (hours)')#, size=12)\n    #cbar.ax.tick_params(lab"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "=12)\n    #cbar.ax.tick_params(labelsize=10)\n    \n    plt.title('Circumpo"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": "on of Zero Curtain Events')#, size=14, pad=20)\n    \n    plt.tight_l"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "set_label('Number of Events', size=12, labelpad=10)\n    cbar1.ax.ti"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "=10)\n    cbar1.ax.tick_params(labelsize=10)\n    ax1.set_title('Spatial D"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": "tion of Zero Curtain Events', size=14, pad=20)\n    ax1.set_title('S"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": "tion of Zero Curtain Events', size=14, pad=20)\n    # Calculate vali"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": " #ax1.set_xlabel('Longitude', size=12, labelpad=10)\n    #ax1.set_yl"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "  #ax1.set_ylabel('Latitude', size=12, labelpad=10)\n    #ax1.tick_p"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "lpad=10)\n    #ax1.tick_params(labelsize=10)\n    #ax1.grid(True, alpha=0."
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "abel('Mean Duration (hours)', size=12, labelpad=10)\n    cbar2.ax.ti"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "=10)\n    cbar2.ax.tick_params(labelsize=10)\n    ax2.set_title('Mean Zero"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": "ro Curtain Duration by Site', size=14, pad=20)\n    ax2.set_extent(["
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": " #ax2.set_xlabel('Longitude', size=12, labelpad=10)\n    #ax2.set_yl"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "  #ax2.set_ylabel('Latitude', size=12, labelpad=10)\n    #ax2.tick_p"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "lpad=10)\n    #ax2.tick_params(labelsize=10)\n    #ax2.grid(True, alpha=0."
    },
    {
      "cell": 173,
      "variable": "title_fontsize",
      "value": "12",
      "context": "e='Depth Zone',\n              title_fontsize=12,\n              fontsize=10,\n "
    },
    {
      "cell": 173,
      "variable": "fontsize",
      "value": "10",
      "context": "le_fontsize=12,\n              fontsize=10,\n              bbox_to_anchor"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": " Distribution by Depth Zone', size=14, pad=20)\n    ax3.set_extent(["
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": " #ax3.set_xlabel('Longitude', size=12, labelpad=10)\n    #ax3.set_yl"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "  #ax3.set_ylabel('Latitude', size=12, labelpad=10)\n    #ax3.tick_p"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "lpad=10)\n    #ax3.tick_params(labelsize=10)\n    #ax3.grid(True, alpha=0."
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "set_label('Duration (hours)', size=12)\n    cbar4.ax.tick_params(lab"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "=12)\n    cbar4.ax.tick_params(labelsize=10)\n    ax4.set_title('Circumpol"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": "tion of Zero Curtain Events', size=14, pad=20)\n    \n    plt.tight_l"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "10",
      "context": "set_label('Number of Events', size=10)\n    cbar1.ax.tick_params(lab"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "8",
      "context": "=10)\n    cbar1.ax.tick_params(labelsize=8)\n    ax1.set_title('Spatial D"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "tion of Zero Curtain Events', size=12, pad=10)\n    \n    \n    # Subp"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "abel('Mean Duration (hours)', size=12, labelpad=10)\n    cbar2.ax.ti"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "=10)\n    cbar2.ax.tick_params(labelsize=10)\n    ax2.set_title('Mean Zero"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": "ro Curtain Duration by Site', size=14, pad=20)\n    \n    \n    # Subp"
    },
    {
      "cell": 173,
      "variable": "title_fontsize",
      "value": "12",
      "context": "e='Depth Zone',\n              title_fontsize=12,\n              fontsize=10,\n "
    },
    {
      "cell": 173,
      "variable": "fontsize",
      "value": "10",
      "context": "le_fontsize=12,\n              fontsize=10,\n              bbox_to_anchor"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": " Distribution by Depth Zone', size=14, pad=20)\n    \n    \n    # Subp"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "set_label('Duration (hours)', size=12)\n    cbar4.ax.tick_params(lab"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "=12)\n    cbar4.ax.tick_params(labelsize=10)\n    ax4.set_title('Circumpol"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": "tion of Zero Curtain Events', size=14, pad=20)\n    \n    plt.tight_l"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "el('Mean Duration (hours)')#, size=12, labelpad=10)\n    #cbar.ax.ti"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "=10)\n    #cbar.ax.tick_params(labelsize=10)\n    \n    plt.title('Mean Zer"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": " Curtain Duration by Site')#, size=14, pad=20)\n    \n    plt.tight_l"
    },
    {
      "cell": 173,
      "variable": "title_fontsize",
      "value": "12",
      "context": "le='Depth Zone',\n             title_fontsize=12,\n             fontsize=10,\n  "
    },
    {
      "cell": 173,
      "variable": "fontsize",
      "value": "10",
      "context": "tle_fontsize=12,\n             fontsize=10,\n             bbox_to_anchor="
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": "istribution by Depth Zone')#, size=14, pad=20)\n    \n    plt.tight_l"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "12",
      "context": "t_label('Duration (hours)')#, size=12)\n    #cbar.ax.tick_params(lab"
    },
    {
      "cell": 173,
      "variable": "labelsize",
      "value": "10",
      "context": "=12)\n    #cbar.ax.tick_params(labelsize=10)\n    \n    plt.title('Circumpo"
    },
    {
      "cell": 173,
      "variable": "size",
      "value": "14",
      "context": "on of Zero Curtain Events')#, size=14, pad=20)\n    \n    plt.tight_l"
    },
    {
      "cell": 173,
      "variable": "fontsize",
      "value": "10",
      "context": "abel('Mean Temperature (\u00b0C)', fontsize=10)\n    ax1.set_xlabel('Depth (m"
    },
    {
      "cell": 173,
      "variable": "markersize",
      "value": "5",
      "context": "' ').title(),\n                markersize=5)\n        \n        # Add trend"
    },
    {
      "cell": 173,
      "variable": "markersize",
      "value": "6",
      "context": "='o',\n                        markersize=6,\n                        line"
    },
    {
      "cell": 173,
      "variable": "capsize",
      "value": "4",
      "context": "th=2,\n                        capsize=4,\n                        capt"
    },
    {
      "cell": 173,
      "variable": "fontsize",
      "value": "12",
      "context": "  \n    ax1.set_xlabel('Year', fontsize=12)\n    ax1.set_ylabel('Mean Dur"
    },
    {
      "cell": 173,
      "variable": "fontsize",
      "value": "12",
      "context": "ation (hours)', color=color1, fontsize=12)\n    ax1.tick_params(axis='y'"
    },
    {
      "cell": 173,
      "variable": "markersize",
      "value": "6",
      "context": "='s',\n                        markersize=6,\n                        line"
    },
    {
      "cell": 173,
      "variable": "capsize",
      "value": "4",
      "context": "th=2,\n                        capsize=4,\n                        capt"
    },
    {
      "cell": 173,
      "variable": "fontsize",
      "value": "12",
      "context": "ean Depth (m)', color=color2, fontsize=12)\n    ax2.tick_params(axis='y'"
    },
    {
      "cell": 173,
      "variable": "fontsize",
      "value": "10",
      "context": "'upper right', \n              fontsize=10)\n    \n    # Set title\n    plt"
    },
    {
      "cell": 173,
      "variable": "fontsize",
      "value": "14",
      "context": "on and Depth', \n              fontsize=14, \n              pad=20)\n    \n"
    },
    {
      "cell": 195,
      "variable": "sequence_length",
      "value": "6",
      "context": "g(merged_df, enhanced_events, sequence_length=6):\n#     \"\"\"\n#     Prepare tim"
    },
    {
      "cell": 195,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 195,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 195,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 195,
      "variable": "kernel_size",
      "value": "3",
      "context": "   conv1 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='"
    },
    {
      "cell": 195,
      "variable": "kernel_size",
      "value": "5",
      "context": "   conv2 = Conv1D(filters=32, kernel_size=5, activation='relu', padding='"
    },
    {
      "cell": 195,
      "variable": "kernel_size",
      "value": "7",
      "context": "   conv3 = Conv1D(filters=32, kernel_size=7, activation='relu', padding='"
    },
    {
      "cell": 195,
      "variable": "sequence_length",
      "value": "24",
      "context": "ces with sliding window\n#     sequence_length = 24  # 24 time steps - adjust bas"
    },
    {
      "cell": 195,
      "variable": "test_size",
      "value": "0.3",
      "context": "temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
    },
    {
      "cell": 195,
      "variable": "test_size",
      "value": "0.5",
      "context": "in_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_"
    },
    {
      "cell": 195,
      "variable": "batch_size",
      "value": "32",
      "context": "nt(\"Training model...\")\n#     batch_size = 32\n#     epochs = 100\n    \n#    "
    },
    {
      "cell": 195,
      "variable": "sequence_length",
      "value": "6",
      "context": "_to_new_data(model, new_data, sequence_length=6):\n#     \"\"\"\n#     Apply a tra"
    },
    {
      "cell": 195,
      "variable": "fontsize",
      "value": "9",
      "context": "nment='bottom',\n#             fontsize=9,\n#             bbox=dict(face"
    },
    {
      "cell": 195,
      "variable": "fontsize",
      "value": "12",
      "context": "e('Zero Curtain Event Count', fontsize=12)\n    \n#     # Plot 2: Mean du"
    },
    {
      "cell": 195,
      "variable": "fontsize",
      "value": "12",
      "context": "'Mean Zero Curtain Duration', fontsize=12)\n    \n#     # Add comprehensi"
    },
    {
      "cell": 195,
      "variable": "fontsize",
      "value": "14",
      "context": "0:.1f}-{p90:.1f}h',\n#         fontsize=14\n#     )\n    \n#     plt.tight_"
    },
    {
      "cell": 195,
      "variable": "fontsize",
      "value": "14",
      "context": "p between Detection Methods', fontsize=14)\n#             plt.savefig(os"
    },
    {
      "cell": 195,
      "variable": "sequence_length",
      "value": "24",
      "context": "ged_df,\n#                     sequence_length=24\n#                 )\n         "
    },
    {
      "cell": 195,
      "variable": "batch_size",
      "value": "500",
      "context": "sults', use_checkpoints=True, batch_size=500):\n#     \"\"\"\n#     Run the com"
    },
    {
      "cell": 195,
      "variable": "sequence_length",
      "value": "24",
      "context": "                              sequence_length=24\n#                            "
    },
    {
      "cell": 195,
      "variable": "batch_size",
      "value": "500",
      "context": "  use_checkpoints=True,\n#     batch_size=500  # Adjust based on memory con"
    },
    {
      "cell": 197,
      "variable": "chunk_size",
      "value": "1000000",
      "context": "ck: Process in chunks\n        chunk_size = 1000000\n        unique_combos = set()"
    },
    {
      "cell": 197,
      "variable": "sequence_length",
      "value": "6",
      "context": "ntly(feather_path, events_df, sequence_length=6, \n                           "
    },
    {
      "cell": 197,
      "variable": "batch_size",
      "value": "500",
      "context": "             output_dir=None, batch_size=500, start_batch=0):\n    \"\"\"\n    "
    },
    {
      "cell": 197,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 197,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 197,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 197,
      "variable": "batch_size",
      "value": "32",
      "context": "rint(\"Training model...\")\n    batch_size = 32  # Adjust based on available "
    },
    {
      "cell": 197,
      "variable": "batch_size",
      "value": "50",
      "context": "h, output_base_dir='results', batch_size=50):\n    \"\"\"\n    Run the complet"
    },
    {
      "cell": 197,
      "variable": "sequence_length",
      "value": "24",
      "context": "ents,\n                        sequence_length=24,  # Use 24 time steps as in y"
    },
    {
      "cell": 197,
      "variable": "sequence_length",
      "value": "24",
      "context": "path,\n                        sequence_length=24,\n                        outp"
    },
    {
      "cell": 197,
      "variable": "sequence_length",
      "value": "6",
      "context": "iciently(model, feather_path, sequence_length=6, \n                           "
    },
    {
      "cell": 197,
      "variable": "batch_size",
      "value": "50",
      "context": "             output_dir=None, batch_size=50):\n    \"\"\"\n    Apply a trained"
    },
    {
      "cell": 197,
      "variable": "fontsize",
      "value": "9",
      "context": "ignment='bottom',\n            fontsize=9,\n            bbox=dict(faceco"
    },
    {
      "cell": 197,
      "variable": "fontsize",
      "value": "12",
      "context": "e('Zero Curtain Event Count', fontsize=12)\n    \n    # Plot 2: Mean dura"
    },
    {
      "cell": 197,
      "variable": "fontsize",
      "value": "12",
      "context": "'Mean Zero Curtain Duration', fontsize=12)\n    \n    # Add comprehensive"
    },
    {
      "cell": 197,
      "variable": "fontsize",
      "value": "14",
      "context": "p10:.1f}-{p90:.1f}h',\n        fontsize=14\n    )\n    \n    plt.tight_layo"
    },
    {
      "cell": 197,
      "variable": "batch_size",
      "value": "1000",
      "context": "hysical events in batches\n    batch_size = 1000\n    for i in range(0, len(phy"
    },
    {
      "cell": 197,
      "variable": "fontsize",
      "value": "14",
      "context": "p between Detection Methods', fontsize=14)\n            plt.savefig(os.p"
    },
    {
      "cell": 197,
      "variable": "site_batch_size",
      "value": "20",
      "context": " 'enhanced'),\n                site_batch_size=20,\n                checkpoint_i"
    },
    {
      "cell": 197,
      "variable": "sequence_length",
      "value": "24",
      "context": "d_events,\n                    sequence_length=24,\n                    output_d"
    },
    {
      "cell": 197,
      "variable": "batch_size",
      "value": "20",
      "context": "l_data'),\n                    batch_size=20\n                )\n           "
    },
    {
      "cell": 197,
      "variable": "sequence_length",
      "value": "24",
      "context": "her_path,\n                    sequence_length=24,\n                    output_d"
    },
    {
      "cell": 197,
      "variable": "batch_size",
      "value": "20",
      "context": "ctions'),\n                    batch_size=20\n                )\n           "
    },
    {
      "cell": 208,
      "variable": "sequence_length",
      "value": "6",
      "context": "e_min', 'datetime_max']),\n    sequence_length=6,\n    output_dir='zero_curtain"
    },
    {
      "cell": 208,
      "variable": "batch_size",
      "value": "50",
      "context": "peline/modeling/ml_data',\n    batch_size=50\n)"
    },
    {
      "cell": 209,
      "variable": "batch_size",
      "value": "50",
      "context": "tion from where it left off\n# batch_size = 50  # Same as before\n# X, y, met"
    },
    {
      "cell": 209,
      "variable": "sequence_length",
      "value": "6",
      "context": "   events_df=events_df,\n#     sequence_length=6,\n#     output_dir=output_dir,"
    },
    {
      "cell": 212,
      "variable": "test_fraction",
      "value": "0.2",
      "context": "in_test_split(X, y, metadata, test_fraction=0.2, val_fraction=0.15):\n#     \"\""
    },
    {
      "cell": 212,
      "variable": "val_fraction",
      "value": "0.15",
      "context": " metadata, test_fraction=0.2, val_fraction=0.15):\n#     \"\"\"\n#     Spatiotempo"
    },
    {
      "cell": 215,
      "variable": "min_batch_size",
      "value": "1000",
      "context": "ze to reasonable limits\n#     min_batch_size = 1000\n#     max_batch_size = 50000\n"
    },
    {
      "cell": 215,
      "variable": "max_batch_size",
      "value": "50000",
      "context": "  min_batch_size = 1000\n#     max_batch_size = 50000\n#     batch_size = max(min(ba"
    },
    {
      "cell": 215,
      "variable": "leaf_size",
      "value": "40",
      "context": "a(latitudes, longitudes, k=5, leaf_size=40, batch_size=None, n_jobs=-1):"
    },
    {
      "cell": 218,
      "variable": "leaf_size",
      "value": "40",
      "context": "=longitudes,\n#     k=5,\n#     leaf_size=40,\n#     batch_size=100000,  # "
    },
    {
      "cell": 218,
      "variable": "batch_size",
      "value": "100000",
      "context": "=5,\n#     leaf_size=40,\n#     batch_size=100000,  # Much larger batch size fo"
    },
    {
      "cell": 221,
      "variable": "chunk_size",
      "value": "1000000",
      "context": ": Process in chunks\n#         chunk_size = 1000000\n#         unique_combos = set"
    },
    {
      "cell": 221,
      "variable": "chunk_size",
      "value": "1000000",
      "context": ": Process in chunks\n#         chunk_size = 1000000\n#         unique_combos = set"
    },
    {
      "cell": 221,
      "variable": "sequence_length",
      "value": "6",
      "context": "ntly(feather_path, events_df, sequence_length=6, \n#                          "
    },
    {
      "cell": 221,
      "variable": "batch_size",
      "value": "500",
      "context": "             output_dir=None, batch_size=500, start_batch=0):\n#     \"\"\"\n# "
    },
    {
      "cell": 221,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 221,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 221,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 221,
      "variable": "batch_size",
      "value": "32",
      "context": "nt(\"Training model...\")\n#     batch_size = 32  # Adjust based on available "
    },
    {
      "cell": 221,
      "variable": "batch_size",
      "value": "50",
      "context": "h, output_base_dir='results', batch_size=50):\n#     \"\"\"\n#     Run the com"
    },
    {
      "cell": 221,
      "variable": "sequence_length",
      "value": "24",
      "context": "ts,\n#                         sequence_length=24,  # Use 24 time steps as in y"
    },
    {
      "cell": 221,
      "variable": "sequence_length",
      "value": "24",
      "context": "th,\n#                         sequence_length=24,\n#                         ou"
    },
    {
      "cell": 221,
      "variable": "sequence_length",
      "value": "6",
      "context": "iciently(model, feather_path, sequence_length=6, \n#                          "
    },
    {
      "cell": 221,
      "variable": "batch_size",
      "value": "50",
      "context": "             output_dir=None, batch_size=50):\n#     \"\"\"\n#     Apply a tra"
    },
    {
      "cell": 221,
      "variable": "fontsize",
      "value": "9",
      "context": "nment='bottom',\n#             fontsize=9,\n#             bbox=dict(face"
    },
    {
      "cell": 221,
      "variable": "fontsize",
      "value": "12",
      "context": "e('Zero Curtain Event Count', fontsize=12)\n    \n#     # Plot 2: Mean du"
    },
    {
      "cell": 221,
      "variable": "fontsize",
      "value": "12",
      "context": "'Mean Zero Curtain Duration', fontsize=12)\n    \n#     # Add comprehensi"
    },
    {
      "cell": 221,
      "variable": "fontsize",
      "value": "14",
      "context": "0:.1f}-{p90:.1f}h',\n#         fontsize=14\n#     )\n    \n#     plt.tight_"
    },
    {
      "cell": 221,
      "variable": "batch_size",
      "value": "1000",
      "context": "sical events in batches\n#     batch_size = 1000\n#     for i in range(0, len(p"
    },
    {
      "cell": 221,
      "variable": "fontsize",
      "value": "14",
      "context": "p between Detection Methods', fontsize=14)\n#             plt.savefig(os"
    },
    {
      "cell": 221,
      "variable": "site_batch_size",
      "value": "20",
      "context": "enhanced'),\n#                 site_batch_size=20,\n#                 checkpoint"
    },
    {
      "cell": 221,
      "variable": "sequence_length",
      "value": "24",
      "context": "events,\n#                     sequence_length=24,\n#                     output"
    },
    {
      "cell": 221,
      "variable": "batch_size",
      "value": "20",
      "context": "data'),\n#                     batch_size=20\n#                 )\n         "
    },
    {
      "cell": 221,
      "variable": "sequence_length",
      "value": "24",
      "context": "r_path,\n#                     sequence_length=24,\n#                     output"
    },
    {
      "cell": 221,
      "variable": "batch_size",
      "value": "20",
      "context": "ions'),\n#                     batch_size=20\n#                 )\n         "
    },
    {
      "cell": 221,
      "variable": "sequence_length",
      "value": "6",
      "context": "   events_df=events_df,\n#     sequence_length=6,\n#     output_dir='zero_curta"
    },
    {
      "cell": 221,
      "variable": "batch_size",
      "value": "50",
      "context": "line/modeling/ml_data',\n#     batch_size=50\n# )\n\n# merge_result = merge_b"
    },
    {
      "cell": 221,
      "variable": "test_fraction",
      "value": "0.2",
      "context": "in_test_split(X, y, metadata, test_fraction=0.2, val_fraction=0.15):\n# #     "
    },
    {
      "cell": 221,
      "variable": "val_fraction",
      "value": "0.15",
      "context": " metadata, test_fraction=0.2, val_fraction=0.15):\n# #     \"\"\"\n# #     Spatiot"
    },
    {
      "cell": 221,
      "variable": "test_fraction",
      "value": "0.2",
      "context": "sing import StandardScaler\n\n# test_fraction=0.2\n# val_fraction=0.15\n# timesta"
    },
    {
      "cell": 221,
      "variable": "val_fraction",
      "value": "0.15",
      "context": "Scaler\n\n# test_fraction=0.2\n# val_fraction=0.15\n# timestamps = np.array([meta"
    },
    {
      "cell": 221,
      "variable": "min_batch_size",
      "value": "1000",
      "context": "ze to reasonable limits\n#     min_batch_size = 1000\n#     max_batch_size = 50000\n"
    },
    {
      "cell": 221,
      "variable": "max_batch_size",
      "value": "50000",
      "context": "  min_batch_size = 1000\n#     max_batch_size = 50000\n#     batch_size = max(min(ba"
    },
    {
      "cell": 221,
      "variable": "leaf_size",
      "value": "40",
      "context": "a(latitudes, longitudes, k=5, leaf_size=40, batch_size=None, n_jobs=-1):"
    },
    {
      "cell": 221,
      "variable": "leaf_size",
      "value": "40",
      "context": "=longitudes,\n#     k=5,\n#     leaf_size=40,\n#     batch_size=100000,  # "
    },
    {
      "cell": 221,
      "variable": "batch_size",
      "value": "100000",
      "context": "=5,\n#     leaf_size=40,\n#     batch_size=100000,  # Much larger batch size fo"
    },
    {
      "cell": 224,
      "variable": "batch_size",
      "value": "50000",
      "context": "tances(cartesian_points, k=5, batch_size=50000):\n#     \"\"\"\n#     Calculate d"
    },
    {
      "cell": 224,
      "variable": "batch_size",
      "value": "50000",
      "context": "patial_density(lat, lon, k=5, batch_size=50000):\n#     \"\"\"\n#     Calculate s"
    },
    {
      "cell": 224,
      "variable": "fontsize",
      "value": "14",
      "context": "patial Density Distribution', fontsize=14)\n        \n#         # Save or"
    },
    {
      "cell": 226,
      "variable": "test_fraction",
      "value": "0.2",
      "context": "sing import StandardScaler\n\n# test_fraction=0.2\n# val_fraction=0.15\n# timesta"
    },
    {
      "cell": 226,
      "variable": "val_fraction",
      "value": "0.15",
      "context": "Scaler\n\n# test_fraction=0.2\n# val_fraction=0.15\n# timestamps = np.array([meta"
    },
    {
      "cell": 227,
      "variable": "min_batch_size",
      "value": "1000",
      "context": "size to reasonable limits\n    min_batch_size = 1000\n    max_batch_size = 50000\n  "
    },
    {
      "cell": 227,
      "variable": "max_batch_size",
      "value": "50000",
      "context": "    min_batch_size = 1000\n    max_batch_size = 50000\n    batch_size = max(min(batc"
    },
    {
      "cell": 227,
      "variable": "leaf_size",
      "value": "40",
      "context": "y(latitudes, longitudes, k=5, leaf_size=40, batch_size=None, n_jobs=4, \n"
    },
    {
      "cell": 227,
      "variable": "test_size",
      "value": "0.2",
      "context": "emporal_split(X, y, metadata, test_size=0.2, val_size=0.15, \n            "
    },
    {
      "cell": 227,
      "variable": "val_size",
      "value": "0.15",
      "context": ", y, metadata, test_size=0.2, val_size=0.15, \n                           "
    },
    {
      "cell": 229,
      "variable": "leaf_size",
      "value": "40",
      "context": "des=longitudes, \n    k=5,\n    leaf_size=40,\n    batch_size=100000,\n    n"
    },
    {
      "cell": 229,
      "variable": "batch_size",
      "value": "100000",
      "context": "   k=5,\n    leaf_size=40,\n    batch_size=100000,\n    n_jobs=recommended_jobs\n"
    },
    {
      "cell": 230,
      "variable": "test_size",
      "value": "0.2",
      "context": ", \n    metadata=metadata,\n    test_size=0.2, \n    val_size=0.15\n)"
    },
    {
      "cell": 230,
      "variable": "val_size",
      "value": "0.15",
      "context": "data,\n    test_size=0.2, \n    val_size=0.15\n)"
    },
    {
      "cell": 236,
      "variable": "chunk_size",
      "value": "1000000",
      "context": "ck: Process in chunks\n        chunk_size = 1000000\n        unique_combos = set()"
    },
    {
      "cell": 236,
      "variable": "sequence_length",
      "value": "6",
      "context": "ntly(feather_path, events_df, sequence_length=6, \n                           "
    },
    {
      "cell": 236,
      "variable": "batch_size",
      "value": "500",
      "context": "             output_dir=None, batch_size=500, start_batch=0):\n    \"\"\"\n    "
    },
    {
      "cell": 236,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 236,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 236,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 236,
      "variable": "batch_size",
      "value": "32",
      "context": "rint(\"Training model...\")\n    batch_size = 32  # Adjust based on available "
    },
    {
      "cell": 236,
      "variable": "batch_size",
      "value": "50",
      "context": "h, output_base_dir='results', batch_size=50):\n    \"\"\"\n    Run the complet"
    },
    {
      "cell": 236,
      "variable": "sequence_length",
      "value": "24",
      "context": "ents,\n                        sequence_length=24,  # Use 24 time steps as in y"
    },
    {
      "cell": 236,
      "variable": "sequence_length",
      "value": "24",
      "context": "path,\n                        sequence_length=24,\n                        outp"
    },
    {
      "cell": 236,
      "variable": "sequence_length",
      "value": "6",
      "context": "iciently(model, feather_path, sequence_length=6, \n                           "
    },
    {
      "cell": 236,
      "variable": "batch_size",
      "value": "50",
      "context": "             output_dir=None, batch_size=50):\n    \"\"\"\n    Apply a trained"
    },
    {
      "cell": 236,
      "variable": "fontsize",
      "value": "9",
      "context": "ignment='bottom',\n            fontsize=9,\n            bbox=dict(faceco"
    },
    {
      "cell": 236,
      "variable": "fontsize",
      "value": "12",
      "context": "e('Zero Curtain Event Count', fontsize=12)\n    \n    # Plot 2: Mean dura"
    },
    {
      "cell": 236,
      "variable": "fontsize",
      "value": "12",
      "context": "'Mean Zero Curtain Duration', fontsize=12)\n    \n    # Add comprehensive"
    },
    {
      "cell": 236,
      "variable": "fontsize",
      "value": "14",
      "context": "p10:.1f}-{p90:.1f}h',\n        fontsize=14\n    )\n    \n    plt.tight_layo"
    },
    {
      "cell": 236,
      "variable": "batch_size",
      "value": "1000",
      "context": "hysical events in batches\n    batch_size = 1000\n    for i in range(0, len(phy"
    },
    {
      "cell": 236,
      "variable": "fontsize",
      "value": "14",
      "context": "p between Detection Methods', fontsize=14)\n            plt.savefig(os.p"
    },
    {
      "cell": 236,
      "variable": "site_batch_size",
      "value": "20",
      "context": " 'enhanced'),\n                site_batch_size=20,\n                checkpoint_i"
    },
    {
      "cell": 236,
      "variable": "sequence_length",
      "value": "24",
      "context": "d_events,\n                    sequence_length=24,\n                    output_d"
    },
    {
      "cell": 236,
      "variable": "batch_size",
      "value": "20",
      "context": "l_data'),\n                    batch_size=20\n                )\n           "
    },
    {
      "cell": 236,
      "variable": "sequence_length",
      "value": "24",
      "context": "her_path,\n                    sequence_length=24,\n                    output_d"
    },
    {
      "cell": 236,
      "variable": "batch_size",
      "value": "20",
      "context": "ctions'),\n                    batch_size=20\n                )\n           "
    },
    {
      "cell": 239,
      "variable": "test_size",
      "value": "0.2",
      "context": "it(\n#         X, y, metadata, test_size=0.2, val_size=0.15, checkpoint_di"
    },
    {
      "cell": 239,
      "variable": "val_size",
      "value": "0.15",
      "context": ", y, metadata, test_size=0.2, val_size=0.15, checkpoint_dir=checkpoint_di"
    },
    {
      "cell": 239,
      "variable": "batch_size",
      "value": "32",
      "context": "ing model training...\")\n#     batch_size = 32  # Adjust based on available "
    },
    {
      "cell": 241,
      "variable": "batch_size",
      "value": "32",
      "context": "elf, X_file, y_file, indices, batch_size=32, shuffle=True, weights=None):"
    },
    {
      "cell": 253,
      "variable": "batch_size",
      "value": "32",
      "context": "__init__(self, X, y, indices, batch_size=32, shuffle=True, weights=None):"
    },
    {
      "cell": 254,
      "variable": "batch_size",
      "value": "1024",
      "context": "enerator(X, y, train_indices, batch_size=1024, shuffle=True, weights=sample"
    },
    {
      "cell": 254,
      "variable": "batch_size",
      "value": "1024",
      "context": "aGenerator(X, y, val_indices, batch_size=1024, shuffle=False)\n# test_gen = "
    },
    {
      "cell": 254,
      "variable": "batch_size",
      "value": "1024",
      "context": "Generator(X, y, test_indices, batch_size=1024, shuffle=False)"
    },
    {
      "cell": 255,
      "variable": "buffer_size",
      "value": "10000",
      "context": "_generator, output_signature, buffer_size=10000):\n#     \"\"\"\n#     Create a Te"
    },
    {
      "cell": 261,
      "variable": "buffer_size",
      "value": "10000",
      "context": "_signature, has_weights=True, buffer_size=10000):\n    \"\"\"\n    Create a Tensor"
    },
    {
      "cell": 262,
      "variable": "batch_size",
      "value": "512",
      "context": "nerator(X, y, subset_indices, batch_size=512, shuffle=True, weights=subset"
    },
    {
      "cell": 263,
      "variable": "subset_fraction",
      "value": "0.001",
      "context": "subset_fraction = 0.001\nsubset_size = int(len(val_ind"
    },
    {
      "cell": 263,
      "variable": "batch_size",
      "value": "1024",
      "context": "nerator(X, y, subset_indices, batch_size=1024, shuffle=False)"
    },
    {
      "cell": 264,
      "variable": "subset_fraction",
      "value": "0.001",
      "context": "subset_fraction = 0.001\nsubset_size = int(len(test_in"
    },
    {
      "cell": 264,
      "variable": "batch_size",
      "value": "1024",
      "context": "Generator(X, y, test_indices, batch_size=1024, shuffle=False)"
    },
    {
      "cell": 274,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 274,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 274,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 278,
      "variable": "batch_size",
      "value": "32",
      "context": "__init__(self, X, y, indices, batch_size=32, shuffle=True, weights=None):"
    },
    {
      "cell": 279,
      "variable": "batch_size",
      "value": "32",
      "context": "elf, X_file, y_file, indices, batch_size=32, shuffle=True, weights=None):"
    },
    {
      "cell": 280,
      "variable": "batch_size",
      "value": "256",
      "context": "                              batch_size=256, weights=sample_weights)\n# va"
    },
    {
      "cell": 280,
      "variable": "batch_size",
      "value": "256",
      "context": "                              batch_size=256)"
    },
    {
      "cell": 281,
      "variable": "buffer_size",
      "value": "10000",
      "context": "_generator, output_signature, buffer_size=10000):\n#     \"\"\"\n#     Create a Te"
    },
    {
      "cell": 282,
      "variable": "batch_size",
      "value": "1024",
      "context": "dices, \n#                     batch_size=1024, chunks=10, epochs_per_chunk="
    },
    {
      "cell": 287,
      "variable": "batch_size",
      "value": "256",
      "context": "aset(X_file, y_file, indices, batch_size=256, shuffle=True, \n             "
    },
    {
      "cell": 288,
      "variable": "batch_size",
      "value": "256",
      "context": "                              batch_size=256, chunks=20, epochs_per_chunk="
    },
    {
      "cell": 289,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 289,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n       "
    },
    {
      "cell": 289,
      "variable": "test_batch_size",
      "value": "5000",
      "context": "cess test data in batches\n    test_batch_size = 5000\n    num_test_batches = int(np"
    },
    {
      "cell": 298,
      "variable": "batch_size",
      "value": "256",
      "context": " output_dir=output_dir,\n#     batch_size=256,          # Standard batch si"
    },
    {
      "cell": 298,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  # Standard batch size\n#     chunk_size=25000,        # Process 25k samples"
    },
    {
      "cell": 300,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 300,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 300,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 300,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 300,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 300,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 300,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 300,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 300,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 300,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 300,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 300,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 300,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 300,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 300,
      "variable": "test_batch_size",
      "value": "5000",
      "context": "ss test data in batches\n#     test_batch_size = 5000\n#     num_test_batches = int("
    },
    {
      "cell": 301,
      "variable": "batch_size",
      "value": "256",
      "context": " output_dir=output_dir,\n#     batch_size=256,          # Standard batch si"
    },
    {
      "cell": 301,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  # Standard batch size\n#     chunk_size=25000,        # Process 25k samples"
    },
    {
      "cell": 303,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 303,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 303,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 303,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 303,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 303,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 303,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 303,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 303,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 303,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n       "
    },
    {
      "cell": 304,
      "variable": "batch_size",
      "value": "256",
      "context": " output_dir=output_dir,\n#     batch_size=256,\n#     chunk_size=25000,\n#   "
    },
    {
      "cell": 304,
      "variable": "chunk_size",
      "value": "25000",
      "context": ",\n#     batch_size=256,\n#     chunk_size=25000,\n#     epochs_per_chunk=2,\n# "
    },
    {
      "cell": 305,
      "variable": "batch_size",
      "value": "256",
      "context": "   output_dir=output_dir,\n    batch_size=256,\n    chunk_size=25000,\n    ep"
    },
    {
      "cell": 305,
      "variable": "chunk_size",
      "value": "25000",
      "context": "_dir,\n    batch_size=256,\n    chunk_size=25000,\n    epochs_per_chunk=2,\n    "
    },
    {
      "cell": 312,
      "variable": "batch_size",
      "value": "1000",
      "context": "test_predictions = []\n        batch_size = 1000\n        \n        for i in ran"
    },
    {
      "cell": 326,
      "variable": "chunk_size",
      "value": "1000000",
      "context": ": Process in chunks\n#         chunk_size = 1000000\n#         unique_combos = set"
    },
    {
      "cell": 326,
      "variable": "sequence_length",
      "value": "6",
      "context": "ntly(feather_path, events_df, sequence_length=6, \n#                          "
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "500",
      "context": "             output_dir=None, batch_size=500, start_batch=0):\n#     \"\"\"\n# "
    },
    {
      "cell": 326,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 326,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 326,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "32",
      "context": "nt(\"Training model...\")\n#     batch_size = 32  # Adjust based on available "
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "50",
      "context": "h, output_base_dir='results', batch_size=50):\n#     \"\"\"\n#     Run the com"
    },
    {
      "cell": 326,
      "variable": "sequence_length",
      "value": "24",
      "context": "ts,\n#                         sequence_length=24,  # Use 24 time steps as in y"
    },
    {
      "cell": 326,
      "variable": "sequence_length",
      "value": "24",
      "context": "th,\n#                         sequence_length=24,\n#                         ou"
    },
    {
      "cell": 326,
      "variable": "sequence_length",
      "value": "6",
      "context": "iciently(model, feather_path, sequence_length=6, \n#                          "
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "50",
      "context": "             output_dir=None, batch_size=50):\n#     \"\"\"\n#     Apply a tra"
    },
    {
      "cell": 326,
      "variable": "fontsize",
      "value": "9",
      "context": "nment='bottom',\n#             fontsize=9,\n#             bbox=dict(face"
    },
    {
      "cell": 326,
      "variable": "fontsize",
      "value": "12",
      "context": "e('Zero Curtain Event Count', fontsize=12)\n    \n#     # Plot 2: Mean du"
    },
    {
      "cell": 326,
      "variable": "fontsize",
      "value": "12",
      "context": "'Mean Zero Curtain Duration', fontsize=12)\n    \n#     # Add comprehensi"
    },
    {
      "cell": 326,
      "variable": "fontsize",
      "value": "14",
      "context": "0:.1f}-{p90:.1f}h',\n#         fontsize=14\n#     )\n    \n#     plt.tight_"
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "1000",
      "context": "sical events in batches\n#     batch_size = 1000\n#     for i in range(0, len(p"
    },
    {
      "cell": 326,
      "variable": "fontsize",
      "value": "14",
      "context": "p between Detection Methods', fontsize=14)\n#             plt.savefig(os"
    },
    {
      "cell": 326,
      "variable": "site_batch_size",
      "value": "20",
      "context": "enhanced'),\n#                 site_batch_size=20,\n#                 checkpoint"
    },
    {
      "cell": 326,
      "variable": "sequence_length",
      "value": "24",
      "context": "events,\n#                     sequence_length=24,\n#                     output"
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "20",
      "context": "data'),\n#                     batch_size=20\n#                 )\n         "
    },
    {
      "cell": 326,
      "variable": "sequence_length",
      "value": "24",
      "context": "r_path,\n#                     sequence_length=24,\n#                     output"
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "20",
      "context": "ions'),\n#                     batch_size=20\n#                 )\n         "
    },
    {
      "cell": 326,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 326,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 326,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "256",
      "context": "aset(X_file, y_file, indices, batch_size=256, shuffle=True, \n#            "
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "256",
      "context": "                              batch_size=256, chunks=20, epochs_per_chunk="
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 326,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 326,
      "variable": "test_batch_size",
      "value": "5000",
      "context": "ss test data in batches\n#     test_batch_size = 5000\n#     num_test_batches = int("
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 326,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 326,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 326,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 326,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 326,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "256",
      "context": "utput_dir=output_dir,\n# #     batch_size=256,\n# #     chunk_size=25000,\n# "
    },
    {
      "cell": 326,
      "variable": "chunk_size",
      "value": "25000",
      "context": "#     batch_size=256,\n# #     chunk_size=25000,\n# #     epochs_per_chunk=2,\n"
    },
    {
      "cell": 326,
      "variable": "batch_size",
      "value": "256",
      "context": " output_dir=output_dir,\n#     batch_size=256,\n#     chunk_size=25000,\n#   "
    },
    {
      "cell": 326,
      "variable": "chunk_size",
      "value": "25000",
      "context": ",\n#     batch_size=256,\n#     chunk_size=25000,\n#     epochs_per_chunk=2,\n# "
    },
    {
      "cell": 331,
      "variable": "batch_size",
      "value": "256",
      "context": "le, y_file, test_indices,\n    batch_size=256, shuffle=False\n)"
    },
    {
      "cell": 337,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=10000, epochs_per"
    },
    {
      "cell": 337,
      "variable": "chunk_size",
      "value": "10000",
      "context": "  output_dir, batch_size=256, chunk_size=10000, epochs_per_chunk=2):\n#     \""
    },
    {
      "cell": 337,
      "variable": "test_batch_size",
      "value": "5000",
      "context": "easonable-sized batches\n#     test_batch_size = 5000\n#     num_test_batches = int("
    },
    {
      "cell": 338,
      "variable": "batch_size",
      "value": "16",
      "context": "del, X_mmap, y_mmap, indices, batch_size=16):\n#     \"\"\"Evaluate model in "
    },
    {
      "cell": 338,
      "variable": "batch_size",
      "value": "16",
      "context": "tches(model, X_mmap, indices, batch_size=16):\n#     \"\"\"Generate predictio"
    },
    {
      "cell": 341,
      "variable": "mini_batch_size",
      "value": "8",
      "context": " output_dir=output_dir,\n#     mini_batch_size=8,           # Process only 8 s"
    },
    {
      "cell": 341,
      "variable": "virtual_batch_size",
      "value": "256",
      "context": "les at a time in memory\n#     virtual_batch_size=256,      # Accumulate gradients "
    },
    {
      "cell": 341,
      "variable": "chunk_size",
      "value": "2000",
      "context": "o simulate batch of 256\n#     chunk_size=2000,             # Process 2000 s"
    },
    {
      "cell": 347,
      "variable": "test_size",
      "value": "0.2",
      "context": "it(\n#         X, y, metadata, test_size=0.2, val_size=0.15, checkpoint_di"
    },
    {
      "cell": 347,
      "variable": "val_size",
      "value": "0.15",
      "context": ", y, metadata, test_size=0.2, val_size=0.15, checkpoint_dir=checkpoint_di"
    },
    {
      "cell": 347,
      "variable": "batch_size",
      "value": "32",
      "context": "ing model training...\")\n#     batch_size = 32  # Adjust based on available "
    },
    {
      "cell": 347,
      "variable": "batch_size",
      "value": "32",
      "context": "elf, X_file, y_file, indices, batch_size=32, shuffle=True, weights=None):"
    },
    {
      "cell": 347,
      "variable": "batch_size",
      "value": "32",
      "context": "__init__(self, X, y, indices, batch_size=32, shuffle=True, weights=None):"
    },
    {
      "cell": 347,
      "variable": "batch_size",
      "value": "1024",
      "context": "enerator(X, y, train_indices, batch_size=1024, shuffle=True, weights=sample"
    },
    {
      "cell": 347,
      "variable": "batch_size",
      "value": "1024",
      "context": "aGenerator(X, y, val_indices, batch_size=1024, shuffle=False)\n# test_gen = "
    },
    {
      "cell": 347,
      "variable": "batch_size",
      "value": "1024",
      "context": "Generator(X, y, test_indices, batch_size=1024, shuffle=False)\n\n# def create"
    },
    {
      "cell": 347,
      "variable": "buffer_size",
      "value": "10000",
      "context": "_generator, output_signature, buffer_size=10000):\n#     \"\"\"\n#     Create a Te"
    },
    {
      "cell": 347,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 347,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 347,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 347,
      "variable": "batch_size",
      "value": "32",
      "context": "__init__(self, X, y, indices, batch_size=32, shuffle=True, weights=None):"
    },
    {
      "cell": 347,
      "variable": "batch_size",
      "value": "1024",
      "context": "enerator(X, y, train_indices, batch_size=1024, shuffle=True, weights=sample"
    },
    {
      "cell": 347,
      "variable": "batch_size",
      "value": "1024",
      "context": "aGenerator(X, y, val_indices, batch_size=1024, shuffle=False)\n# test_gen = "
    },
    {
      "cell": 347,
      "variable": "batch_size",
      "value": "1024",
      "context": "Generator(X, y, test_indices, batch_size=1024, shuffle=False)\n\n# print(trai"
    },
    {
      "cell": 347,
      "variable": "buffer_size",
      "value": "10000",
      "context": "_generator, output_signature, buffer_size=10000):\n#     \"\"\"\n#     Create a Te"
    },
    {
      "cell": 349,
      "variable": "buffer_size",
      "value": "10000",
      "context": "_signature, has_weights=True, buffer_size=10000):\n    \"\"\"\n    Create a Tensor"
    },
    {
      "cell": 350,
      "variable": "subset_fraction",
      "value": "0.001",
      "context": "subset_fraction = 0.001\nsubset_size = int(len(train_i"
    },
    {
      "cell": 350,
      "variable": "batch_size",
      "value": "512",
      "context": "nerator(X, y, subset_indices, batch_size=512, shuffle=True, weights=subset"
    },
    {
      "cell": 351,
      "variable": "subset_fraction",
      "value": "0.001",
      "context": "subset_fraction = 0.001\nsubset_size = int(len(val_ind"
    },
    {
      "cell": 351,
      "variable": "batch_size",
      "value": "1024",
      "context": "nerator(X, y, subset_indices, batch_size=1024, shuffle=False)"
    },
    {
      "cell": 352,
      "variable": "subset_fraction",
      "value": "0.001",
      "context": "subset_fraction = 0.001\nsubset_size = int(len(test_in"
    },
    {
      "cell": 352,
      "variable": "batch_size",
      "value": "1024",
      "context": "Generator(X, y, test_indices, batch_size=1024, shuffle=False)"
    },
    {
      "cell": 366,
      "variable": "batch_size",
      "value": "10000",
      "context": "rocessing test sequences...\")\nbatch_size = 10000\ncomparison_data = []\ntest_lab"
    },
    {
      "cell": 400,
      "variable": "batch_size",
      "value": "10000",
      "context": "rocessing test sequences...\")\nbatch_size = 10000\ncomparison_data = []\ntest_lab"
    },
    {
      "cell": 422,
      "variable": "batch_size",
      "value": "1000",
      "context": "hysical events in batches\n    batch_size = 1000\n    for i in range(0, len(phy"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "16",
      "context": "p between Detection Methods', fontsize=16)\n            plt.savefig(os.p"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "12",
      "context": "lt.xlabel('Duration (hours)', fontsize=12)\n        plt.ylabel('Frequenc"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "12",
      "context": "abel('Frequency (log scale)', fontsize=12)\n        plt.title('Compariso"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "16",
      "context": "tain Duration Distributions', fontsize=16)\n        plt.legend(fontsize="
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "12",
      "context": "ntsize=16)\n        plt.legend(fontsize=12)\n        plt.grid(alpha=0.3)\n"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "12",
      "context": " \n        plt.xlabel('Month', fontsize=12)\n        plt.ylabel('Number o"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "12",
      "context": "label('Number of Event Days', fontsize=12)\n        plt.title('Monthly D"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "16",
      "context": "tion of Zero Curtain Events', fontsize=16)\n        plt.xticks(x, month_"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "12",
      "context": "nth_names)\n        plt.legend(fontsize=12)\n        plt.grid(axis='y', a"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "12",
      "context": "     ax.set_xlabel('Site ID', fontsize=12)\n        ax.set_ylabel('Numbe"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "12",
      "context": "label('Number of Event Days', fontsize=12)\n        ax.set_title('Site-l"
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "16",
      "context": "Top 20 Sites by Event Count', fontsize=16)\n        ax.set_xticks(x)\n   "
    },
    {
      "cell": 422,
      "variable": "fontsize",
      "value": "12",
      "context": "ha='right')\n        ax.legend(fontsize=12)\n        ax.grid(axis='y', al"
    },
    {
      "cell": 425,
      "variable": "chunk_size",
      "value": "1000000",
      "context": ": Process in chunks\n#         chunk_size = 1000000\n#         unique_combos = set"
    },
    {
      "cell": 425,
      "variable": "sequence_length",
      "value": "6",
      "context": "ntly(feather_path, events_df, sequence_length=6, \n#                          "
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "500",
      "context": "             output_dir=None, batch_size=500, start_batch=0):\n#     \"\"\"\n# "
    },
    {
      "cell": 425,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 425,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 425,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "32",
      "context": "nt(\"Training model...\")\n#     batch_size = 32  # Adjust based on available "
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "50",
      "context": "h, output_base_dir='results', batch_size=50):\n#     \"\"\"\n#     Run the com"
    },
    {
      "cell": 425,
      "variable": "sequence_length",
      "value": "24",
      "context": "ts,\n#                         sequence_length=24,  # Use 24 time steps as in y"
    },
    {
      "cell": 425,
      "variable": "sequence_length",
      "value": "24",
      "context": "th,\n#                         sequence_length=24,\n#                         ou"
    },
    {
      "cell": 425,
      "variable": "sequence_length",
      "value": "6",
      "context": "iciently(model, feather_path, sequence_length=6, \n#                          "
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "50",
      "context": "             output_dir=None, batch_size=50):\n#     \"\"\"\n#     Apply a tra"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "9",
      "context": "nment='bottom',\n#             fontsize=9,\n#             bbox=dict(face"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "e('Zero Curtain Event Count', fontsize=12)\n    \n#     # Plot 2: Mean du"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "'Mean Zero Curtain Duration', fontsize=12)\n    \n#     # Add comprehensi"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "14",
      "context": "0:.1f}-{p90:.1f}h',\n#         fontsize=14\n#     )\n    \n#     plt.tight_"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "1000",
      "context": "sical events in batches\n#     batch_size = 1000\n#     for i in range(0, len(p"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "14",
      "context": "p between Detection Methods', fontsize=14)\n#             plt.savefig(os"
    },
    {
      "cell": 425,
      "variable": "site_batch_size",
      "value": "20",
      "context": "enhanced'),\n#                 site_batch_size=20,\n#                 checkpoint"
    },
    {
      "cell": 425,
      "variable": "sequence_length",
      "value": "24",
      "context": "events,\n#                     sequence_length=24,\n#                     output"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "20",
      "context": "data'),\n#                     batch_size=20\n#                 )\n         "
    },
    {
      "cell": 425,
      "variable": "sequence_length",
      "value": "24",
      "context": "r_path,\n#                     sequence_length=24,\n#                     output"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "20",
      "context": "ions'),\n#                     batch_size=20\n#                 )\n         "
    },
    {
      "cell": 425,
      "variable": "sequence_length",
      "value": "6",
      "context": "min', 'datetime_max']),\n#     sequence_length=6,\n#     output_dir='zero_curta"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "50",
      "context": "line/modeling/ml_data',\n#     batch_size=50\n# )\n\n# merge_result = merge_b"
    },
    {
      "cell": 425,
      "variable": "min_batch_size",
      "value": "1000",
      "context": "ze to reasonable limits\n#     min_batch_size = 1000\n#     max_batch_size = 50000\n"
    },
    {
      "cell": 425,
      "variable": "max_batch_size",
      "value": "50000",
      "context": "  min_batch_size = 1000\n#     max_batch_size = 50000\n#     batch_size = max(min(ba"
    },
    {
      "cell": 425,
      "variable": "leaf_size",
      "value": "40",
      "context": "y(latitudes, longitudes, k=5, leaf_size=40, batch_size=None, n_jobs=4, \n"
    },
    {
      "cell": 425,
      "variable": "test_size",
      "value": "0.2",
      "context": "emporal_split(X, y, metadata, test_size=0.2, val_size=0.15, \n#           "
    },
    {
      "cell": 425,
      "variable": "val_size",
      "value": "0.15",
      "context": ", y, metadata, test_size=0.2, val_size=0.15, \n#                          "
    },
    {
      "cell": 425,
      "variable": "leaf_size",
      "value": "40",
      "context": "longitudes, \n#     k=5,\n#     leaf_size=40,\n#     batch_size=100000,\n#  "
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "100000",
      "context": "=5,\n#     leaf_size=40,\n#     batch_size=100000,\n#     n_jobs=recommended_job"
    },
    {
      "cell": 425,
      "variable": "test_size",
      "value": "0.2",
      "context": "     metadata=metadata,\n#     test_size=0.2, \n#     val_size=0.15\n# )\n\n# "
    },
    {
      "cell": 425,
      "variable": "val_size",
      "value": "0.15",
      "context": ",\n#     test_size=0.2, \n#     val_size=0.15\n# )\n\n# with open(\"zero_curtai"
    },
    {
      "cell": 425,
      "variable": "chunk_size",
      "value": "1000000",
      "context": ": Process in chunks\n#         chunk_size = 1000000\n#         unique_combos = set"
    },
    {
      "cell": 425,
      "variable": "site_batch_size",
      "value": "20",
      "context": "                              site_batch_size=20, checkpoint_interval=5, \n#   "
    },
    {
      "cell": 425,
      "variable": "site_batch_size",
      "value": "50",
      "context": "ero_curtain_pipeline', \n#     site_batch_size=50, \n#     checkpoint_interval=5"
    },
    {
      "cell": 425,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 425,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 425,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 425,
      "variable": "test_size",
      "value": "0.2",
      "context": "it(\n#         X, y, metadata, test_size=0.2, val_size=0.15, checkpoint_di"
    },
    {
      "cell": 425,
      "variable": "val_size",
      "value": "0.15",
      "context": ", y, metadata, test_size=0.2, val_size=0.15, checkpoint_dir=checkpoint_di"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "32",
      "context": "ing model training...\")\n#     batch_size = 32  # Adjust based on available "
    },
    {
      "cell": 425,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 425,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 425,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "32",
      "context": "elf, X_file, y_file, indices, batch_size=32, shuffle=True, weights=None):"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "32",
      "context": "__init__(self, X, y, indices, batch_size=32, shuffle=True, weights=None):"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "1024",
      "context": "enerator(X, y, train_indices, batch_size=1024, shuffle=True, weights=sample"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "1024",
      "context": "aGenerator(X, y, val_indices, batch_size=1024, shuffle=False)\n# test_gen = "
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "1024",
      "context": "Generator(X, y, test_indices, batch_size=1024, shuffle=False)\n\n# def create"
    },
    {
      "cell": 425,
      "variable": "buffer_size",
      "value": "10000",
      "context": "_generator, output_signature, buffer_size=10000):\n#     \"\"\"\n#     Create a Te"
    },
    {
      "cell": 425,
      "variable": "buffer_size",
      "value": "10000",
      "context": "_signature, has_weights=True, buffer_size=10000):\n#     \"\"\"\n#     Create a Te"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "512",
      "context": "nerator(X, y, subset_indices, batch_size=512, shuffle=True, weights=subset"
    },
    {
      "cell": 425,
      "variable": "subset_fraction",
      "value": "0.001",
      "context": "e, weights=subset_weights)\n\n# subset_fraction = 0.001\n# subset_size = int(len(val_i"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "1024",
      "context": "nerator(X, y, subset_indices, batch_size=1024, shuffle=False)\n\n# subset_fra"
    },
    {
      "cell": 425,
      "variable": "subset_fraction",
      "value": "0.001",
      "context": "_size=1024, shuffle=False)\n\n# subset_fraction = 0.001\n# subset_size = int(len(test_"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "1024",
      "context": "Generator(X, y, test_indices, batch_size=1024, shuffle=False)\n\n# # Create d"
    },
    {
      "cell": 425,
      "variable": "batch_size",
      "value": "1000",
      "context": "sical events in batches\n#     batch_size = 1000\n#     for i in range(0, len(p"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "16",
      "context": "p between Detection Methods', fontsize=16)\n#             plt.savefig(os"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "lt.xlabel('Duration (hours)', fontsize=12)\n#         plt.ylabel('Freque"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "abel('Frequency (log scale)', fontsize=12)\n#         plt.title('Compari"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "16",
      "context": "tain Duration Distributions', fontsize=16)\n#         plt.legend(fontsiz"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "size=16)\n#         plt.legend(fontsize=12)\n#         plt.grid(alpha=0.3"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "#         plt.xlabel('Month', fontsize=12)\n#         plt.ylabel('Number"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "label('Number of Event Days', fontsize=12)\n#         plt.title('Monthly"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "16",
      "context": "tion of Zero Curtain Events', fontsize=16)\n#         plt.xticks(x, mont"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "h_names)\n#         plt.legend(fontsize=12)\n#         plt.grid(axis='y',"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "     ax.set_xlabel('Site ID', fontsize=12)\n#         ax.set_ylabel('Num"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "label('Number of Event Days', fontsize=12)\n#         ax.set_title('Site"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "16",
      "context": "Top 20 Sites by Event Count', fontsize=16)\n#         ax.set_xticks(x)\n#"
    },
    {
      "cell": 425,
      "variable": "fontsize",
      "value": "12",
      "context": "='right')\n#         ax.legend(fontsize=12)\n#         ax.grid(axis='y', "
    },
    {
      "cell": 434,
      "variable": "batch_size",
      "value": "32",
      "context": "__init__(self, X, y, indices, batch_size=32, shuffle=True, weights=None):"
    },
    {
      "cell": 435,
      "variable": "batch_size",
      "value": "256",
      "context": "enerator(X, y, train_indices, batch_size=256, shuffle=True, weights=sample"
    },
    {
      "cell": 435,
      "variable": "batch_size",
      "value": "256",
      "context": "aGenerator(X, y, val_indices, batch_size=256, shuffle=False)\ntest_gen = Da"
    },
    {
      "cell": 435,
      "variable": "batch_size",
      "value": "256",
      "context": "Generator(X, y, test_indices, batch_size=256, shuffle=False)"
    },
    {
      "cell": 439,
      "variable": "batch_size",
      "value": "16",
      "context": "Generator(X, y, test_indices, batch_size=16, shuffle=False)\nevaluation = "
    },
    {
      "cell": 453,
      "variable": "min_batch_size",
      "value": "1000",
      "context": "ze to reasonable limits\n#     min_batch_size = 1000\n#     max_batch_size = 50000\n"
    },
    {
      "cell": 453,
      "variable": "max_batch_size",
      "value": "50000",
      "context": "  min_batch_size = 1000\n#     max_batch_size = 50000\n#     batch_size = max(min(ba"
    },
    {
      "cell": 453,
      "variable": "leaf_size",
      "value": "40",
      "context": "y(latitudes, longitudes, k=5, leaf_size=40, batch_size=None, n_jobs=4, \n"
    },
    {
      "cell": 453,
      "variable": "test_size",
      "value": "0.2",
      "context": "emporal_split(X, y, metadata, test_size=0.2, val_size=0.15, \n#           "
    },
    {
      "cell": 453,
      "variable": "val_size",
      "value": "0.15",
      "context": ", y, metadata, test_size=0.2, val_size=0.15, \n#                          "
    },
    {
      "cell": 453,
      "variable": "leaf_size",
      "value": "40",
      "context": "longitudes, \n#     k=5,\n#     leaf_size=40,\n#     batch_size=100000,\n#  "
    },
    {
      "cell": 453,
      "variable": "batch_size",
      "value": "100000",
      "context": "=5,\n#     leaf_size=40,\n#     batch_size=100000,\n#     n_jobs=recommended_job"
    },
    {
      "cell": 453,
      "variable": "test_size",
      "value": "0.2",
      "context": "     metadata=metadata,\n#     test_size=0.2, \n#     val_size=0.15\n# )\n\n# "
    },
    {
      "cell": 453,
      "variable": "val_size",
      "value": "0.15",
      "context": ",\n#     test_size=0.2, \n#     val_size=0.15\n# )\n\n# with open(\"zero_curtai"
    },
    {
      "cell": 453,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 453,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 453,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 453,
      "variable": "test_size",
      "value": "0.2",
      "context": "it(\n#         X, y, metadata, test_size=0.2, val_size=0.15, checkpoint_di"
    },
    {
      "cell": 453,
      "variable": "val_size",
      "value": "0.15",
      "context": ", y, metadata, test_size=0.2, val_size=0.15, checkpoint_dir=checkpoint_di"
    },
    {
      "cell": 453,
      "variable": "batch_size",
      "value": "32",
      "context": "ing model training...\")\n#     batch_size = 32  # Adjust based on available "
    },
    {
      "cell": 458,
      "variable": "batch_size",
      "value": "8",
      "context": " spatial density weights are\n\nbatch_size = 8\n\nmodel, history, evaluation ="
    },
    {
      "cell": 481,
      "variable": "batch_size",
      "value": "5000",
      "context": "# batch_size = 5000  # Adjust based on memory con"
    },
    {
      "cell": 486,
      "variable": "batch_size",
      "value": "5000",
      "context": "dd points to index in batches\nbatch_size = 5000\nfor i in tqdm(range(0, num_el"
    },
    {
      "cell": 496,
      "variable": "batch_size",
      "value": "10000",
      "context": "rnel density estimates...\")\n# batch_size = 10000\n# depth_log_density = np.zero"
    },
    {
      "cell": 496,
      "variable": "minlength",
      "value": "13",
      "context": "p.bincount(timestamps_months, minlength=13)[1:]  # Skip index 0\n# month_"
    },
    {
      "cell": 585,
      "variable": "test_fraction",
      "value": "0.2",
      "context": "st_split(\n    X, y, metadata, test_fraction=0.2, val_fraction=0.15\n)"
    },
    {
      "cell": 585,
      "variable": "val_fraction",
      "value": "0.15",
      "context": " metadata, test_fraction=0.2, val_fraction=0.15\n)"
    },
    {
      "cell": 592,
      "variable": "sample_fraction",
      "value": "0.1",
      "context": "tadata=None, output_dir=None, sample_fraction=0.1):\n    \"\"\"\n    More efficient "
    },
    {
      "cell": 592,
      "variable": "batch_size",
      "value": "256",
      "context": "rint(\"Training model...\")\n    batch_size = 256  # Larger batch size for fast"
    },
    {
      "cell": 594,
      "variable": "sample_fraction",
      "value": "0.001",
      "context": "tput_base_dir, 'sample'),\n    sample_fraction=0.001  # Use 0.1% of data for faste"
    },
    {
      "cell": 598,
      "variable": "cycle_length",
      "value": "10",
      "context": "ng rate schedule\"\"\"\n#         cycle_length = 10\n#         base_lr = 1e-4\n#   "
    },
    {
      "cell": 598,
      "variable": "n_splits",
      "value": "5",
      "context": " = StratifiedKFold(\n#         n_splits=5,  # 5-fold cross-validation \n"
    },
    {
      "cell": 598,
      "variable": "batch_size",
      "value": "32",
      "context": "will stop early\n#             batch_size=32,\n#             callbacks=[\n# "
    },
    {
      "cell": 598,
      "variable": "batch_size",
      "value": "256",
      "context": "aset(X_file, y_file, indices, batch_size=256, shuffle=True, \n#            "
    },
    {
      "cell": 598,
      "variable": "batch_size",
      "value": "32",
      "context": "                  output_dir, batch_size=32, chunk_size=25000, epochs_per"
    },
    {
      "cell": 598,
      "variable": "chunk_size",
      "value": "25000",
      "context": "   output_dir, batch_size=32, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 598,
      "variable": "test_batch_size",
      "value": "5000",
      "context": "ss test data in batches\n#     test_batch_size = 5000\n#     num_test_batches = int("
    },
    {
      "cell": 598,
      "variable": "batch_size",
      "value": "32",
      "context": "ces,\n#     output_dir, \n#     batch_size=32, \n#     chunk_size=10000, \n# "
    },
    {
      "cell": 598,
      "variable": "chunk_size",
      "value": "10000",
      "context": " \n#     batch_size=32, \n#     chunk_size=10000, \n#     epochs_per_chunk=2, \n"
    },
    {
      "cell": 598,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 598,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n# #    "
    },
    {
      "cell": 598,
      "variable": "test_batch_size",
      "value": "5000",
      "context": " test data in batches\n# #     test_batch_size = 5000\n# #     num_test_batches = in"
    },
    {
      "cell": 598,
      "variable": "n_splits",
      "value": "5",
      "context": "ld\n#     cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=4"
    },
    {
      "cell": 598,
      "variable": "capsize",
      "value": "5",
      "context": "rtance[sorted_idx],\n#         capsize=5\n#     )\n#     plt.title('Cros"
    },
    {
      "cell": 598,
      "variable": "batch_size",
      "value": "50",
      "context": "ut_base_dir='results', \n#     batch_size=50, \n#     start_chunk=0\n# ):\n# "
    },
    {
      "cell": 598,
      "variable": "batch_size",
      "value": "32",
      "context": "output_dir,\n#                 batch_size=32,  # Reduced batch size\n#     "
    },
    {
      "cell": 598,
      "variable": "chunk_size",
      "value": "10000",
      "context": " batch size\n#                 chunk_size=10000,  # Smaller chunks\n#         "
    },
    {
      "cell": 598,
      "variable": "batch_size",
      "value": "50",
      "context": "_base_dir, \n#                 batch_size=50, \n#                 start_chu"
    },
    {
      "cell": 599,
      "variable": "batch_size",
      "value": "256",
      "context": "aset(X_file, y_file, indices, batch_size=256, shuffle=True, \n             "
    },
    {
      "cell": 599,
      "variable": "chunk_size",
      "value": "1000",
      "context": "educe memory pressure\n        chunk_size = 1000\n        num_chunks = (len(ind"
    },
    {
      "cell": 599,
      "variable": "mini_batch_size",
      "value": "100",
      "context": "n smaller batches\n            mini_batch_size = 100\n            for i in range(0,"
    },
    {
      "cell": 599,
      "variable": "batch_size",
      "value": "256",
      "context": "aset(X_file, y_file, indices, batch_size=256, shuffle=True, \n             "
    },
    {
      "cell": 599,
      "variable": "chunk_size",
      "value": "1000",
      "context": "educe memory pressure\n        chunk_size = 1000\n        num_chunks = (len(ind"
    },
    {
      "cell": 599,
      "variable": "mini_batch_size",
      "value": "100",
      "context": "n smaller batches\n            mini_batch_size = 100\n            for i in range(0,"
    },
    {
      "cell": 599,
      "variable": "batch_size",
      "value": "32",
      "context": "indices,\n    output_dir, \n    batch_size=32, \n    chunk_size=5000,  # Red"
    },
    {
      "cell": 599,
      "variable": "chunk_size",
      "value": "5000",
      "context": "dir, \n    batch_size=32, \n    chunk_size=5000,  # Reduced chunk size\n    ep"
    },
    {
      "cell": 599,
      "variable": "sub_chunk_size",
      "value": "1000",
      "context": "chunks for processing\n        sub_chunk_size = 1000  # Process in smaller batches"
    },
    {
      "cell": 599,
      "variable": "batch_size",
      "value": "32",
      "context": "le, test_indices, output_dir, batch_size=32):\n    \"\"\"\n    Memory-efficien"
    },
    {
      "cell": 599,
      "variable": "test_batch_size",
      "value": "1000",
      "context": "cess test data in batches\n    test_batch_size = 1000  # Small batch size for memor"
    },
    {
      "cell": 599,
      "variable": "batch_size",
      "value": "256",
      "context": "aset(X_file, y_file, indices, batch_size=256, shuffle=True, \n             "
    },
    {
      "cell": 599,
      "variable": "chunk_size",
      "value": "1000",
      "context": "educe memory pressure\n        chunk_size = 1000\n        num_chunks = (len(ind"
    },
    {
      "cell": 599,
      "variable": "mini_batch_size",
      "value": "100",
      "context": "n smaller batches\n            mini_batch_size = 100\n            for i in range(0,"
    },
    {
      "cell": 599,
      "variable": "batch_size",
      "value": "32",
      "context": "indices,\n    output_dir, \n    batch_size=32, \n    chunk_size=5000,  # Red"
    },
    {
      "cell": 599,
      "variable": "chunk_size",
      "value": "5000",
      "context": "dir, \n    batch_size=32, \n    chunk_size=5000,  # Reduced chunk size\n    ep"
    },
    {
      "cell": 599,
      "variable": "sub_chunk_size",
      "value": "1000",
      "context": "chunks for processing\n        sub_chunk_size = 1000  # Process in smaller batches"
    },
    {
      "cell": 599,
      "variable": "batch_size",
      "value": "32",
      "context": "le, test_indices, output_dir, batch_size=32):\n    \"\"\"\n    Memory-efficien"
    },
    {
      "cell": 599,
      "variable": "test_batch_size",
      "value": "1000",
      "context": "cess test data in batches\n    test_batch_size = 1000  # Small batch size for memor"
    },
    {
      "cell": 599,
      "variable": "batch_size",
      "value": "16",
      "context": "h, \n    output_base_dir, \n    batch_size=16, \n    start_chunk=0,\n    max_"
    },
    {
      "cell": 599,
      "variable": "chunk_size",
      "value": "2500",
      "context": "_size=batch_size,\n            chunk_size=2500,  # Smaller chunks for memory"
    },
    {
      "cell": 599,
      "variable": "batch_size",
      "value": "256",
      "context": "peline/modeling',\n            batch_size=256,\n            start_chunk=0,  "
    },
    {
      "cell": 600,
      "variable": "batch_size",
      "value": "16",
      "context": "indices,\n    output_dir, \n    batch_size=16, \n    chunk_size=2500,  # Sma"
    },
    {
      "cell": 600,
      "variable": "chunk_size",
      "value": "2500",
      "context": "dir, \n    batch_size=16, \n    chunk_size=2500,  # Smaller chunk size\n    ep"
    },
    {
      "cell": 600,
      "variable": "sub_chunk_size",
      "value": "500",
      "context": "chunks for processing\n        sub_chunk_size = 500  # Process in smaller batches"
    },
    {
      "cell": 600,
      "variable": "batch_size",
      "value": "16",
      "context": "#     output_base_dir, \n#     batch_size=16, \n#     start_chunk=0,\n#     "
    },
    {
      "cell": 600,
      "variable": "chunk_size",
      "value": "2500",
      "context": "ize=batch_size,\n#             chunk_size=2500,  # Smaller chunks for memory"
    },
    {
      "cell": 600,
      "variable": "batch_size",
      "value": "16",
      "context": "line/modeling',\n#             batch_size=16,\n#             start_chunk=0,"
    },
    {
      "cell": 600,
      "variable": "batch_size",
      "value": "16",
      "context": "indices,\n    output_dir, \n    batch_size=16, \n    chunk_size=2500,  # Sma"
    },
    {
      "cell": 600,
      "variable": "chunk_size",
      "value": "2500",
      "context": "dir, \n    batch_size=16, \n    chunk_size=2500,  # Smaller chunk size\n    ep"
    },
    {
      "cell": 600,
      "variable": "sub_chunk_size",
      "value": "500",
      "context": "chunks for processing\n        sub_chunk_size = 500  # Process in smaller batches"
    },
    {
      "cell": 600,
      "variable": "batch_size",
      "value": "16",
      "context": "h, \n    output_base_dir, \n    batch_size=16, \n    start_chunk=0,\n    max_"
    },
    {
      "cell": 600,
      "variable": "chunk_size",
      "value": "2500",
      "context": "_size=batch_size,\n            chunk_size=2500,  # Smaller chunks for memory"
    },
    {
      "cell": 600,
      "variable": "batch_size",
      "value": "16",
      "context": "peline/modeling',\n            batch_size=16,\n            start_chunk=0,  "
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "step_size",
      "value": "2000",
      "context": "        max_lr=0.001,\n        step_size=2000,\n        mode='triangular2'\n "
    },
    {
      "cell": 606,
      "variable": "step_size",
      "value": "2000",
      "context": "    max_lr=0.001,\n            step_size=2000,\n            mode='triangular"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": ", chunk_X, chunk_y, val_data, batch_size=256, epochs=3, class_weight=None)"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=20000, epochs_per"
    },
    {
      "cell": 606,
      "variable": "chunk_size",
      "value": "20000",
      "context": "  output_dir, batch_size=256, chunk_size=20000, epochs_per_chunk=3, \n       "
    },
    {
      "cell": 606,
      "variable": "load_batch_size",
      "value": "5000",
      "context": " size for loading\n            load_batch_size = 5000\n            for i in range(0,"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "ces, val_indices, output_dir, batch_size=256, epochs=3):\n    os.makedirs(o"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "500",
      "context": "cess test data in batches\n    batch_size = 500  # Smaller batch size for mor"
    },
    {
      "cell": 606,
      "variable": "sub_batch_size",
      "value": "50",
      "context": "r chunks...\")\n                sub_batch_size = 50  # Much smaller batch\n       "
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "put_dir=output_dir,\n#         batch_size=256,\n#         chunk_size=20000, "
    },
    {
      "cell": 606,
      "variable": "chunk_size",
      "value": "20000",
      "context": "    batch_size=256,\n#         chunk_size=20000,  # Smaller chunks for better"
    },
    {
      "cell": 606,
      "variable": "fontsize",
      "value": "14",
      "context": "odel Performance (F1 Score)', fontsize=14)\n                plt.savefig("
    },
    {
      "cell": 606,
      "variable": "capsize",
      "value": "5",
      "context": "portance_df['Std'], fmt='o-', capsize=5, linewidth=2, markersize=8)\n "
    },
    {
      "cell": 606,
      "variable": "markersize",
      "value": "8",
      "context": "'o-', capsize=5, linewidth=2, markersize=8)\n        plt.title('Importanc"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, epochs=3, class_weight=None,"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "\n                 output_dir, batch_size=256, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "effective_batch_size",
      "value": "64",
      "context": "es to avoid memory issues\n    effective_batch_size = 64  # Keep this smaller for stab"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "32",
      "context": "epochs=1,\n                    batch_size=32,\n                    class_we"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "chunk_size",
      "value": "100",
      "context": "in chunks for stability\n#     chunk_size = 100\n#     for i in range(0, len(v"
    },
    {
      "cell": 606,
      "variable": "mini_batch_size",
      "value": "32",
      "context": "ini-batch sizes\n#             mini_batch_size = 32  # Smaller, more stable mini-"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "16",
      "context": "ochs=1,\n#                     batch_size=16,\n#                     class_"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "16",
      "context": "ochs=1,\n#                     batch_size=16,\n#                     class_"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "1000",
      "context": "ss test data in batches\n#     batch_size = 1000\n#     num_batches = int(np.ce"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "mini_batch_size",
      "value": "32",
      "context": " mini-batch sizes\n            mini_batch_size = 32  # Smaller, more stable mini-"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "1000",
      "context": "cess test data in batches\n    batch_size = 1000\n    num_batches = int(np.ceil"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "512",
      "context": "                  output_dir, batch_size=512, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "1024",
      "context": "                  output_dir, batch_size=1024, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "512",
      "context": "                  output_dir, batch_size=512, max_epochs=100, class_weight"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "512",
      "context": "                  output_dir, batch_size=512, max_epochs=100, class_weight"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "128",
      "context": "                  output_dir, batch_size=128, max_epochs=100, class_weight"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "utput_dir=output_dir,\n        batch_size=256,\n        epochs=3,\n        cl"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "step_size",
      "value": "2000",
      "context": "      max_lr=0.001,\n#         step_size=2000,\n#         mode='triangular2'"
    },
    {
      "cell": 606,
      "variable": "step_size",
      "value": "2000",
      "context": "  max_lr=0.001,\n#             step_size=2000,\n#             mode='triangul"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": ", chunk_X, chunk_y, val_data, batch_size=256, epochs=3, class_weight=None)"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=20000, epochs_per"
    },
    {
      "cell": 606,
      "variable": "chunk_size",
      "value": "20000",
      "context": "  output_dir, batch_size=256, chunk_size=20000, epochs_per_chunk=3, \n#      "
    },
    {
      "cell": 606,
      "variable": "load_batch_size",
      "value": "5000",
      "context": "ize for loading\n#             load_batch_size = 5000\n#             for i in range("
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "500",
      "context": "ss test data in batches\n#     batch_size = 500  # Smaller batch size for mor"
    },
    {
      "cell": 606,
      "variable": "sub_batch_size",
      "value": "50",
      "context": "chunks...\")\n#                 sub_batch_size = 50  # Much smaller batch\n#      "
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "500",
      "context": "ss test data in batches\n#     batch_size = 500  # Smaller batch size for mor"
    },
    {
      "cell": 606,
      "variable": "sub_batch_size",
      "value": "50",
      "context": "chunks...\")\n#                 sub_batch_size = 50  # Much smaller batch\n#      "
    },
    {
      "cell": 606,
      "variable": "fontsize",
      "value": "14",
      "context": "odel Performance (F1 Score)', fontsize=14)\n#                 plt.savefi"
    },
    {
      "cell": 606,
      "variable": "capsize",
      "value": "5",
      "context": "portance_df['Std'], fmt='o-', capsize=5, linewidth=2, markersize=8)\n#"
    },
    {
      "cell": 606,
      "variable": "markersize",
      "value": "8",
      "context": "'o-', capsize=5, linewidth=2, markersize=8)\n#         plt.title('Importa"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, epochs=3, class_weight=None,"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "effective_batch_size",
      "value": "64",
      "context": " to avoid memory issues\n#     effective_batch_size = 64  # Keep this smaller for stab"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "32",
      "context": "ochs=1,\n#                     batch_size=32,\n#                     class_"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "mini_batch_size",
      "value": "32",
      "context": "ini-batch sizes\n#             mini_batch_size = 32  # Smaller, more stable mini-"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "1000",
      "context": "ss test data in batches\n#     batch_size = 1000\n#     num_batches = int(np.ce"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "512",
      "context": "                  output_dir, batch_size=512, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "1024",
      "context": "                  output_dir, batch_size=1024, class_weight=None, start_bat"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "512",
      "context": "                  output_dir, batch_size=512, max_epochs=100, class_weight"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "1024",
      "context": "put_dir=output_dir,\n#         batch_size=1024,\n#         max_epochs=100,  #"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 606,
      "variable": "step_size",
      "value": "2000",
      "context": "        max_lr=0.001,\n        step_size=2000,\n        mode='triangular2'\n "
    },
    {
      "cell": 606,
      "variable": "step_size",
      "value": "2000",
      "context": "    max_lr=0.001,\n            step_size=2000,\n            mode='triangular"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=20000, epochs_per"
    },
    {
      "cell": 606,
      "variable": "chunk_size",
      "value": "20000",
      "context": "  output_dir, batch_size=256, chunk_size=20000, epochs_per_chunk=3, \n       "
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "1000",
      "context": "cess test data in batches\n    batch_size = 1000\n    num_batches = int(np.ceil"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "put_dir=output_dir,\n#         batch_size=256,\n#         chunk_size=20000, "
    },
    {
      "cell": 606,
      "variable": "chunk_size",
      "value": "20000",
      "context": "    batch_size=256,\n#         chunk_size=20000,  # Smaller chunks for better"
    },
    {
      "cell": 606,
      "variable": "fontsize",
      "value": "14",
      "context": "odel Performance (F1 Score)', fontsize=14)\n        plt.savefig(os.path."
    },
    {
      "cell": 606,
      "variable": "capsize",
      "value": "5",
      "context": "portance_df['Std'], fmt='o-', capsize=5, linewidth=2, markersize=8)\n "
    },
    {
      "cell": 606,
      "variable": "markersize",
      "value": "8",
      "context": "'o-', capsize=5, linewidth=2, markersize=8)\n    plt.title('Importance of"
    },
    {
      "cell": 606,
      "variable": "batch_size",
      "value": "256",
      "context": "utput_dir=output_dir,\n        batch_size=256,\n        chunk_size=20000,\n  "
    },
    {
      "cell": 606,
      "variable": "chunk_size",
      "value": "20000",
      "context": "      batch_size=256,\n        chunk_size=20000,\n        epochs_per_chunk=3,\n"
    },
    {
      "cell": 611,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 611,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 611,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 612,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 612,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 612,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 613,
      "variable": "step_size",
      "value": "2000",
      "context": "        max_lr=0.001,\n        step_size=2000,\n        mode='triangular2',\n"
    },
    {
      "cell": 614,
      "variable": "step_size",
      "value": "2000",
      "context": "    max_lr=0.001,\n            step_size=2000,\n            mode='triangular"
    },
    {
      "cell": 615,
      "variable": "batch_size",
      "value": "256",
      "context": ", chunk_X, chunk_y, val_data, batch_size=256, epochs=1):\n    \"\"\"\n    Proce"
    },
    {
      "cell": 616,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=10000, epochs_per"
    },
    {
      "cell": 616,
      "variable": "chunk_size",
      "value": "10000",
      "context": "  output_dir, batch_size=256, chunk_size=10000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 616,
      "variable": "load_batch_size",
      "value": "1000",
      "context": "or loading data\n#             load_batch_size = 1000\n#             for i in range("
    },
    {
      "cell": 617,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=10000, epochs_per"
    },
    {
      "cell": 617,
      "variable": "chunk_size",
      "value": "10000",
      "context": "  output_dir, batch_size=256, chunk_size=10000, epochs_per_chunk=3, \n#      "
    },
    {
      "cell": 617,
      "variable": "load_batch_size",
      "value": "1000",
      "context": "ize for loading\n#             load_batch_size = 1000  # Reduced batch size for mor"
    },
    {
      "cell": 618,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=10000, epochs_per"
    },
    {
      "cell": 618,
      "variable": "chunk_size",
      "value": "10000",
      "context": "  output_dir, batch_size=256, chunk_size=10000, epochs_per_chunk=3, \n#      "
    },
    {
      "cell": 618,
      "variable": "load_batch_size",
      "value": "1000",
      "context": "ize for loading\n#             load_batch_size = 1000  # Reduced batch size for mor"
    },
    {
      "cell": 619,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=10000, epochs_per"
    },
    {
      "cell": 619,
      "variable": "chunk_size",
      "value": "10000",
      "context": "  output_dir, batch_size=256, chunk_size=10000, epochs_per_chunk=3, \n       "
    },
    {
      "cell": 619,
      "variable": "load_batch_size",
      "value": "1000",
      "context": " size for loading\n            load_batch_size = 1000  # Reduced batch size for mor"
    },
    {
      "cell": 620,
      "variable": "batch_size",
      "value": "100",
      "context": "ches for better stability\n    batch_size = 100  # Reduced batch size for mor"
    },
    {
      "cell": 620,
      "variable": "sub_batch_size",
      "value": "10",
      "context": "ch_preds = []\n                sub_batch_size = 10\n                for i in rang"
    },
    {
      "cell": 620,
      "variable": "sub_batch_size",
      "value": "10",
      "context": "r chunks...\")\n                sub_batch_size = 10  # Much smaller batch\n       "
    },
    {
      "cell": 621,
      "variable": "fontsize",
      "value": "14",
      "context": "odel Performance (F1 Score)', fontsize=14)\n                    plt.save"
    },
    {
      "cell": 622,
      "variable": "capsize",
      "value": "5",
      "context": "portance_df['Std'], fmt='o-', capsize=5, linewidth=2, markersize=8)\n "
    },
    {
      "cell": 622,
      "variable": "markersize",
      "value": "8",
      "context": "'o-', capsize=5, linewidth=2, markersize=8)\n                plt.title('I"
    },
    {
      "cell": 623,
      "variable": "chunk_size",
      "value": "10000",
      "context": "etter stability\n#             chunk_size = 10000\n            \n#             # "
    },
    {
      "cell": 623,
      "variable": "batch_size",
      "value": "256",
      "context": "output_dir,\n#                 batch_size=256,\n#                 chunk_size"
    },
    {
      "cell": 624,
      "variable": "chunk_size",
      "value": "10000",
      "context": "ld model every 5 chunks\n#     chunk_size = 10000\n    \n#     # Create log direc"
    },
    {
      "cell": 624,
      "variable": "batch_size",
      "value": "64",
      "context": "ochs=3,\n#                     batch_size=64,\n#                     verbos"
    },
    {
      "cell": 625,
      "variable": "chunk_size",
      "value": "10000",
      "context": "uild model every 5 chunks\n    chunk_size = 10000\n    \n    # Create log directo"
    },
    {
      "cell": 625,
      "variable": "batch_size",
      "value": "64",
      "context": "epochs=3,\n                    batch_size=64,\n                    verbose="
    },
    {
      "cell": 627,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 627,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 627,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 627,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=10000, epochs_per"
    },
    {
      "cell": 627,
      "variable": "chunk_size",
      "value": "10000",
      "context": "  output_dir, batch_size=256, chunk_size=10000, epochs_per_chunk=3, \n       "
    },
    {
      "cell": 627,
      "variable": "load_batch_size",
      "value": "1000",
      "context": "e for loading\n                load_batch_size = 1000  # Reduced batch size for mor"
    },
    {
      "cell": 627,
      "variable": "batch_size",
      "value": "100",
      "context": " for better stability\n        batch_size = 100  # Reduced batch size for mor"
    },
    {
      "cell": 627,
      "variable": "sub_batch_size",
      "value": "10",
      "context": "reds = []\n                    sub_batch_size = 10\n                    for i in "
    },
    {
      "cell": 627,
      "variable": "sub_batch_size",
      "value": "10",
      "context": "unks...\")\n                    sub_batch_size = 10  # Much smaller batch\n       "
    },
    {
      "cell": 627,
      "variable": "chunk_size",
      "value": "10000",
      "context": " better stability\n            chunk_size = 10000\n            \n            # Tr"
    },
    {
      "cell": 627,
      "variable": "batch_size",
      "value": "256",
      "context": "output_dir,\n            #     batch_size=256,\n            #     chunk_size"
    },
    {
      "cell": 630,
      "variable": "step_size",
      "value": "2000",
      "context": "        max_lr=0.001,\n        step_size=2000,\n        mode='triangular2',\n"
    },
    {
      "cell": 630,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=16, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 630,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=16, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 630,
      "variable": "step_size",
      "value": "1000",
      "context": "   # Lower max LR\n            step_size=1000,\n            mode='triangular"
    },
    {
      "cell": 630,
      "variable": "batch_size",
      "value": "64",
      "context": "        output_dir, epochs=3, batch_size=64, logger=None):\n    \"\"\"\n    Tr"
    },
    {
      "cell": 630,
      "variable": "load_batch_size",
      "value": "1000",
      "context": " to prevent memory spikes\n    load_batch_size = 1000\n    \n    for i in range(0, le"
    },
    {
      "cell": 630,
      "variable": "chunk_size",
      "value": "5000",
      "context": "_dir,\n                        chunk_size=5000, rebuild_interval=5, logger=N"
    },
    {
      "cell": 630,
      "variable": "batch_size",
      "value": "64",
      "context": " epochs per chunk\n            batch_size=64,\n            logger=logger\n  "
    },
    {
      "cell": 630,
      "variable": "chunk_size",
      "value": "5000",
      "context": "dir,\n#                        chunk_size=5000, rebuild_interval=5, logger=N"
    },
    {
      "cell": 630,
      "variable": "batch_size",
      "value": "64",
      "context": "epochs per chunk\n#            batch_size=64,\n#            logger=logger\n#"
    },
    {
      "cell": 630,
      "variable": "batch_size",
      "value": "50",
      "context": "hes for memory efficiency\n    batch_size = 50  # Very small batch size for "
    },
    {
      "cell": 630,
      "variable": "sub_size",
      "value": "10",
      "context": "ch_preds = []\n                sub_size = 10\n                for i in rang"
    },
    {
      "cell": 630,
      "variable": "fontsize",
      "value": "14",
      "context": "odel Performance (F1 Score)', fontsize=14)\n                    plt.save"
    },
    {
      "cell": 630,
      "variable": "chunk_size",
      "value": "5000",
      "context": "adata_file=None, resume=True, chunk_size=5000):\n    \"\"\"\n    Run the full Ze"
    },
    {
      "cell": 630,
      "variable": "test_size",
      "value": "0.1",
      "context": "tal_samples),\n                test_size=0.1,\n                random_state"
    },
    {
      "cell": 630,
      "variable": "test_size",
      "value": "0.11",
      "context": "_val_indices,\n                test_size=0.11,  # ~10% of original data\n   "
    },
    {
      "cell": 632,
      "variable": "batch_size",
      "value": "500",
      "context": "ke predictions in batches\n    batch_size = 500  # Larger batch size for fast"
    },
    {
      "cell": 646,
      "variable": "chunk_size",
      "value": "1000000",
      "context": "ck: Process in chunks\n        chunk_size = 1000000\n        unique_combos = set()"
    },
    {
      "cell": 646,
      "variable": "sequence_length",
      "value": "6",
      "context": "ntly(feather_path, events_df, sequence_length=6, \n                           "
    },
    {
      "cell": 646,
      "variable": "batch_size",
      "value": "500",
      "context": "             output_dir=None, batch_size=500, start_batch=0):\n    \"\"\"\n    "
    },
    {
      "cell": 646,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 646,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 646,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 646,
      "variable": "batch_size",
      "value": "32",
      "context": "rint(\"Training model...\")\n    batch_size = 32  # Adjust based on available "
    },
    {
      "cell": 646,
      "variable": "batch_size",
      "value": "50",
      "context": "h, output_base_dir='results', batch_size=50):\n    \"\"\"\n    Run the complet"
    },
    {
      "cell": 646,
      "variable": "sequence_length",
      "value": "24",
      "context": "ents,\n                        sequence_length=24,  # Use 24 time steps as in y"
    },
    {
      "cell": 646,
      "variable": "sequence_length",
      "value": "24",
      "context": "path,\n                        sequence_length=24,\n                        outp"
    },
    {
      "cell": 646,
      "variable": "sequence_length",
      "value": "6",
      "context": "iciently(model, feather_path, sequence_length=6, \n                           "
    },
    {
      "cell": 646,
      "variable": "batch_size",
      "value": "50",
      "context": "             output_dir=None, batch_size=50):\n    \"\"\"\n    Apply a trained"
    },
    {
      "cell": 646,
      "variable": "fontsize",
      "value": "9",
      "context": "ignment='bottom',\n            fontsize=9,\n            bbox=dict(faceco"
    },
    {
      "cell": 646,
      "variable": "fontsize",
      "value": "12",
      "context": "e('Zero Curtain Event Count', fontsize=12)\n    \n    # Plot 2: Mean dura"
    },
    {
      "cell": 646,
      "variable": "fontsize",
      "value": "12",
      "context": "'Mean Zero Curtain Duration', fontsize=12)\n    \n    # Add comprehensive"
    },
    {
      "cell": 646,
      "variable": "fontsize",
      "value": "14",
      "context": "p10:.1f}-{p90:.1f}h',\n        fontsize=14\n    )\n    \n    plt.tight_layo"
    },
    {
      "cell": 646,
      "variable": "batch_size",
      "value": "1000",
      "context": "hysical events in batches\n    batch_size = 1000\n    for i in range(0, len(phy"
    },
    {
      "cell": 646,
      "variable": "fontsize",
      "value": "14",
      "context": "p between Detection Methods', fontsize=14)\n            plt.savefig(os.p"
    },
    {
      "cell": 646,
      "variable": "site_batch_size",
      "value": "20",
      "context": " 'enhanced'),\n                site_batch_size=20,\n                checkpoint_i"
    },
    {
      "cell": 646,
      "variable": "sequence_length",
      "value": "24",
      "context": "d_events,\n                    sequence_length=24,\n                    output_d"
    },
    {
      "cell": 646,
      "variable": "batch_size",
      "value": "20",
      "context": "l_data'),\n                    batch_size=20\n                )\n           "
    },
    {
      "cell": 646,
      "variable": "sequence_length",
      "value": "24",
      "context": "her_path,\n                    sequence_length=24,\n                    output_d"
    },
    {
      "cell": 646,
      "variable": "batch_size",
      "value": "20",
      "context": "ctions'),\n                    batch_size=20\n                )\n           "
    },
    {
      "cell": 647,
      "variable": "kernel_size",
      "value": "3",
      "context": "   cnn_1 = Conv1D(filters=32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 647,
      "variable": "kernel_size",
      "value": "5",
      "context": "   cnn_2 = Conv1D(filters=32, kernel_size=5, padding='same', activation='"
    },
    {
      "cell": 647,
      "variable": "kernel_size",
      "value": "7",
      "context": "   cnn_3 = Conv1D(filters=32, kernel_size=7, padding='same', activation='"
    },
    {
      "cell": 647,
      "variable": "batch_size",
      "value": "256",
      "context": "aset(X_file, y_file, indices, batch_size=256, shuffle=True, \n             "
    },
    {
      "cell": 647,
      "variable": "batch_size",
      "value": "256",
      "context": "                              batch_size=256, chunks=20, epochs_per_chunk="
    },
    {
      "cell": 647,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 647,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n       "
    },
    {
      "cell": 647,
      "variable": "test_batch_size",
      "value": "5000",
      "context": "cess test data in batches\n    test_batch_size = 5000\n    num_test_batches = int(np"
    },
    {
      "cell": 647,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 647,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 647,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 647,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 647,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 647,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 647,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 647,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n#      "
    },
    {
      "cell": 647,
      "variable": "batch_size",
      "value": "256",
      "context": "                  output_dir, batch_size=256, chunk_size=25000, epochs_per"
    },
    {
      "cell": 647,
      "variable": "chunk_size",
      "value": "25000",
      "context": "  output_dir, batch_size=256, chunk_size=25000, epochs_per_chunk=2, \n       "
    },
    {
      "cell": 647,
      "variable": "batch_size",
      "value": "256",
      "context": " output_dir=output_dir,\n#     batch_size=256,\n#     chunk_size=25000,\n#   "
    },
    {
      "cell": 647,
      "variable": "chunk_size",
      "value": "25000",
      "context": ",\n#     batch_size=256,\n#     chunk_size=25000,\n#     epochs_per_chunk=2,\n# "
    },
    {
      "cell": 647,
      "variable": "batch_size",
      "value": "256",
      "context": "   output_dir=output_dir,\n    batch_size=256,\n    chunk_size=25000,\n    ep"
    },
    {
      "cell": 647,
      "variable": "chunk_size",
      "value": "25000",
      "context": "_dir,\n    batch_size=256,\n    chunk_size=25000,\n    epochs_per_chunk=2,\n    "
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "24",
      "context": "1891-2024)', \n                fontsize=24, fontweight='bold', y=0.98)\n "
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "10",
      "context": "ross the Arctic\",\n            fontsize=10, ha='center', va='bottom', st"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "8",
      "context": "    ha='center', va='center', fontsize=8, color='gray')\n    \n    # Sim"
    },
    {
      "cell": 659,
      "variable": "fraction",
      "value": "0.046",
      "context": "bar = plt.colorbar(sc, ax=ax, fraction=0.046, pad=0.04)\n    cbar.set_label"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "8",
      "context": ".set_xlabel('Duration (hrs)', fontsize=8)\n    inset_ax.set_ylabel('Cou"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "8",
      "context": " inset_ax.set_ylabel('Count', fontsize=8)\n    inset_ax.tick_params(axi"
    },
    {
      "cell": 659,
      "variable": "labelsize",
      "value": "6",
      "context": "ms(axis='both', which='both', labelsize=6)\n    \n    return ax\n\n# Exampl"
    },
    {
      "cell": 659,
      "variable": "size",
      "value": "1000",
      "context": "ndom.gamma(shape=2, scale=50, size=1000),\n        'thickness_m_mean':"
    },
    {
      "cell": 659,
      "variable": "size",
      "value": "1000",
      "context": "dom.gamma(shape=5, scale=0.2, size=1000),\n        'soil_temp_mean': n"
    },
    {
      "cell": 659,
      "variable": "size",
      "value": "1200",
      "context": "ndom.gamma(shape=2, scale=50, size=1200),\n        'thickness_m_mean':"
    },
    {
      "cell": 659,
      "variable": "size",
      "value": "1200",
      "context": "dom.gamma(shape=5, scale=0.2, size=1200),\n        'soil_temp_mean': n"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "10",
      "context": "    ha='center', va='bottom', fontsize=10)\n    \n    for i, rect in enum"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "10",
      "context": "    ha='center', va='bottom', fontsize=10)\n    \n    # Add labels and le"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "9",
      "context": "form=ax.transAxes,\n           fontsize=9, ha='right', va='bottom',\n   "
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "9",
      "context": "                 ha='center', fontsize=9)\n    \n    # Add trend line th"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "9",
      "context": "e=\"arc3\"),\n                   fontsize=9, ha='center')\n    \n    # Crea"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "9",
      "context": "form=ax.transAxes,\n           fontsize=9, va='top',\n           bbox=di"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "10",
      "context": "form=ax.transAxes,\n           fontsize=10, ha='center', va='bottom',\n  "
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "9",
      "context": "form=ax.transAxes,\n           fontsize=9, va='top', ha='left',\n       "
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "9",
      "context": "  color=physics_palette(0.9), fontsize=9, ha='left', va='top')\n    \n  "
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "9",
      "context": "       color=ml_palette(0.9), fontsize=9, ha='left', va='top')\n    \n  "
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "8",
      "context": "  ax.legend(loc='upper left', fontsize=8)\n    \n    # Add statistical s"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "8",
      "context": "form=ax.transAxes,\n           fontsize=8, va='top', ha='left',\n       "
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "12",
      "context": "- 0.05, title,\n               fontsize=12, fontweight='bold', ha='cente"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "11",
      "context": "x.text(0.1 + i*0.3, 0.78, eq, fontsize=11, ha='left')\n    \n    # Add pr"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "10",
      "context": "text(0.1 + i*0.3, 0.48, step, fontsize=10, ha='left')\n    \n    # Add ML"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "10",
      "context": "xt(0.1 + i*0.3, 0.18, metric, fontsize=10, ha='left')\n    \n    # Add ar"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "14",
      "context": "idation Workflow\",\n           fontsize=14, fontweight='bold', ha='cente"
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "9",
      "context": ",\n           \"Zero\\nCurtain\", fontsize=9, ha='center', va='center',\n  "
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "9",
      "context": "pth\",\n           rotation=90, fontsize=9, ha='right', va='center')\n   "
    },
    {
      "cell": 659,
      "variable": "fontsize",
      "value": "9",
      "context": "02, \"Temperature\",\n           fontsize=9, ha='center', va='top')\n    \n"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "14",
      "context": "\n    title = ax.set_title('', fontsize=14, fontweight='bold')\n    \n    "
    },
    {
      "cell": 661,
      "variable": "markersize",
      "value": "10",
      "context": "       markerfacecolor=color, markersize=10, label=season)\n        handle"
    },
    {
      "cell": 661,
      "variable": "sizes",
      "value": "20",
      "context": "ulate point sizes\n            sizes = 20 + 15 * np.log1p(durations / 1"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "10",
      "context": "      va='center', ha='left', fontsize=10)\n    \n    # Add depth scale\n "
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "9",
      "context": "      va='center', ha='left', fontsize=9)\n    \n    # Temperature basel"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "14",
      "context": ", '', transform=ax.transAxes, fontsize=14, \n                   fontweig"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "9",
      "context": "     va='center', ha='right', fontsize=9, color='blue')\n    ax.text(te"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "9",
      "context": "     va='center', ha='right', fontsize=9, color='red')\n    \n    # Init"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "16",
      "context": "Axes, \n                       fontsize=16, fontweight='bold', ha='cente"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "14",
      "context": "onth (Animated Time Series)', fontsize=14)\n    \n    # Start with a slid"
    },
    {
      "cell": 661,
      "variable": "window_size",
      "value": "10",
      "context": "ith a sliding window view\n    window_size = 10\n    \n    # Animation update f"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "20",
      "context": "d Analysis', \n                fontsize=20, fontweight='bold', y=0.98)\n "
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "14",
      "context": "_title = ax_map.set_title('', fontsize=14, fontweight='bold')\n    \n    "
    },
    {
      "cell": 661,
      "variable": "markersize",
      "value": "10",
      "context": "       markerfacecolor=color, markersize=10, label=season)\n        handle"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "10",
      "context": "      va='center', ha='left', fontsize=10)\n    \n    # Add depth scale\n "
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "9",
      "context": "      va='center', ha='left', fontsize=9)\n    \n    # Temperature basel"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "9",
      "context": "     va='center', ha='right', fontsize=9, color='blue')\n    ax_soil.te"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "9",
      "context": "     va='center', ha='right', fontsize=9, color='red')\n    \n    soil_t"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "14",
      "context": " \n                            fontsize=14, fontweight='bold', ha='cente"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "14",
      "context": "ero-Curtain Events by Month', fontsize=14)\n    \n    # 4. Physics panel\n"
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "14",
      "context": "ansform=ax_physics.transAxes, fontsize=14, \n                           "
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "16",
      "context": ".transAxes,\n                  fontsize=16, ha='center', va='center',\n  "
    },
    {
      "cell": 661,
      "variable": "fontsize",
      "value": "12",
      "context": "                              fontsize=12, ha='center', va='center',\n  "
    },
    {
      "cell": 661,
      "variable": "sizes",
      "value": "20",
      "context": "e point sizes\n                sizes = 20 + 15 * np.log1p(durations / 1"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "16",
      "context": "ion from Time Mean)', y=1.02, size=16)\n            plt.tight_layout"
    },
    {
      "cell": 702,
      "variable": "fontsize",
      "value": "8",
      "context": "  plt.clabel(cs, inline=True, fontsize=8, fmt='%.2e')\n        \n       "
    },
    {
      "cell": 702,
      "variable": "fontsize",
      "value": "8",
      "context": "  plt.clabel(cs, inline=True, fontsize=8, fmt='%.2e')\n        \n       "
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "16",
      "context": "anced Visualization', y=1.02, size=16)\n            plt.tight_layout"
    },
    {
      "cell": 702,
      "variable": "labelsize",
      "value": "10",
      "context": ")\n        cbar.ax.tick_params(labelsize=10)\n        plt.title('Time-aver"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "14",
      "context": "ing Probability (1915-2024)', size=14, pad=20)\n        plt.xlabel('"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "12",
      "context": "      plt.xlabel('Longitude', size=12)\n        plt.ylabel('Latitude"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "12",
      "context": "       plt.ylabel('Latitude', size=12)\n        plt.grid(True, alpha"
    },
    {
      "cell": 702,
      "variable": "labelsize",
      "value": "10",
      "context": ")\n        cbar.ax.tick_params(labelsize=10)\n        plt.title('Time-aver"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "14",
      "context": "rmal Wavelength (1915-2024)', size=14, pad=20)\n        plt.xlabel('"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "12",
      "context": "      plt.xlabel('Longitude', size=12)\n        plt.ylabel('Latitude"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "12",
      "context": "       plt.ylabel('Latitude', size=12)\n        plt.grid(True, alpha"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "14",
      "context": "eling Probability Evolution', size=14, pad=20)\n        ax1.set_xlab"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "12",
      "context": "       ax1.set_xlabel('Time', size=12)\n        ax1.set_ylabel('Mean"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "12",
      "context": "'Mean Tunneling Probability', size=12, color=color1)\n        ax1.ti"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "14",
      "context": "hermal Wavelength Evolution', size=14, pad=20)\n        ax2.set_xlab"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "12",
      "context": "       ax2.set_xlabel('Time', size=12)\n        ax2.set_ylabel('Mean"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "12",
      "context": "Mean Thermal Wavelength (m)', size=12, color=color2)\n        ax2.ti"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "12",
      "context": "itle(f'{month_names[month]}', size=12)\n            plt.colorbar(im,"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "16",
      "context": "ns of Tunneling Probability', size=16, y=1.02)\n        plt.tight_la"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "12",
      "context": "itle(f'{month_names[month]}', size=12)\n            plt.colorbar(im,"
    },
    {
      "cell": 702,
      "variable": "size",
      "value": "16",
      "context": "terns of Thermal Wavelength', size=16, y=1.02)\n        plt.tight_la"
    },
    {
      "cell": 725,
      "variable": "window_size",
      "value": "30",
      "context": "ws(self, processed_temp_data, window_size=30):\n#         \"\"\"Create sliding"
    },
    {
      "cell": 725,
      "variable": "val_split",
      "value": "0.2",
      "context": "training(self, windowed_data, val_split=0.2):\n#         \"\"\"Prepare data f"
    },
    {
      "cell": 726,
      "variable": "window_size",
      "value": "30",
      "context": "_for_training(temp_df, zc_df, window_size=30, min_depths=4):\n#     \"\"\"Prep"
    },
    {
      "cell": 726,
      "variable": "batch_size",
      "value": "32",
      "context": "ining_batches(processed_data, batch_size=32, val_split=0.2):\n#     \"\"\"Pre"
    },
    {
      "cell": 726,
      "variable": "val_split",
      "value": "0.2",
      "context": "rocessed_data, batch_size=32, val_split=0.2):\n#     \"\"\"Prepare data batch"
    },
    {
      "cell": 727,
      "variable": "chunk_size",
      "value": "50",
      "context": "ess_in_chunks(temp_df, zc_df, chunk_size=50, window_size=30, min_depths=4"
    },
    {
      "cell": 727,
      "variable": "window_size",
      "value": "30",
      "context": "emp_df, zc_df, chunk_size=50, window_size=30, min_depths=4, depth_range=(-"
    },
    {
      "cell": 727,
      "variable": "batch_size",
      "value": "32",
      "context": "te_tf_dataset(processed_data, batch_size=32, val_split=0.2):\n#     \"\"\"Cre"
    },
    {
      "cell": 727,
      "variable": "val_split",
      "value": "0.2",
      "context": "rocessed_data, batch_size=32, val_split=0.2):\n#     \"\"\"Create TensorFlow "
    },
    {
      "cell": 728,
      "variable": "window_size",
      "value": "30",
      "context": "te(site_id, site_data, zc_df, window_size=30, min_depths=4):\n#     \"\"\"Proc"
    },
    {
      "cell": 728,
      "variable": "chunk_size",
      "value": "10",
      "context": "ess_in_chunks(temp_df, zc_df, chunk_size=10, window_size=30, min_depths=4"
    },
    {
      "cell": 728,
      "variable": "window_size",
      "value": "30",
      "context": "emp_df, zc_df, chunk_size=10, window_size=30, min_depths=4, depth_range=(-"
    },
    {
      "cell": 729,
      "variable": "chunk_size",
      "value": "10",
      "context": "ess_in_chunks(temp_df, zc_df, chunk_size=10)\n#     print(f\"\\nTotal proces"
    },
    {
      "cell": 731,
      "variable": "temporal_window",
      "value": "30",
      "context": "el):\n#     def __init__(self, temporal_window=30, n_depths=4):\n#         super"
    },
    {
      "cell": 731,
      "variable": "window_size",
      "value": "30",
      "context": "eprocess_data(temp_df, zc_df, window_size=30, depth_range=(-2, 20)):\n#    "
    },
    {
      "cell": 731,
      "variable": "batch_size",
      "value": "32",
      "context": "eate_datasets(processed_data, batch_size=32, val_split=0.2):\n#     \"\"\"Cre"
    },
    {
      "cell": 731,
      "variable": "val_split",
      "value": "0.2",
      "context": "rocessed_data, batch_size=32, val_split=0.2):\n#     \"\"\"Create TensorFlow "
    },
    {
      "cell": 733,
      "variable": "window_size",
      "value": "30",
      "context": "ntly(site_id, temp_df, zc_df, window_size=30, depth_range=(-2, 20)):\n    \""
    },
    {
      "cell": 733,
      "variable": "chunk_size",
      "value": "100",
      "context": "\n        windows = []\n        chunk_size = 100  # Process windows in chunks\n"
    },
    {
      "cell": 744,
      "variable": "batch_size",
      "value": "32",
      "context": "(processed_data, n_depths=10, batch_size=32, val_split=0.2):\n#     \"\"\"Cre"
    },
    {
      "cell": 744,
      "variable": "val_split",
      "value": "0.2",
      "context": ", n_depths=10, batch_size=32, val_split=0.2):\n#     \"\"\"Create datasets wi"
    },
    {
      "cell": 747,
      "variable": "batch_size",
      "value": "32",
      "context": "(processed_data, n_depths=10, batch_size=32):\n#     \"\"\"Split processed da"
    },
    {
      "cell": 749,
      "variable": "batch_size",
      "value": "32",
      "context": "(processed_data, n_depths=10, batch_size=32):\n    \"\"\"Split processed data"
    },
    {
      "cell": 753,
      "variable": "window_size",
      "value": "30",
      "context": "ntly(site_id, temp_df, zc_df, window_size=30, depth_range=(-2, 20)):\n#    "
    },
    {
      "cell": 753,
      "variable": "chunk_size",
      "value": "100",
      "context": "       windows = []\n#         chunk_size = 100  # Process windows in chunks\n"
    },
    {
      "cell": 753,
      "variable": "batch_size",
      "value": "32",
      "context": "(processed_data, n_depths=10, batch_size=32):\n#     \"\"\"Split processed da"
    },
    {
      "cell": 754,
      "variable": "temporal_window",
      "value": "30",
      "context": "el):\n#     def __init__(self, temporal_window=30, n_depths=4):\n#         super"
    },
    {
      "cell": 754,
      "variable": "batch_size",
      "value": "32",
      "context": " Training configuration\n#     batch_size = 32\n#     n_samples = len(x_train"
    },
    {
      "cell": 758,
      "variable": "temporal_window",
      "value": "30",
      "context": "el):\n#     def __init__(self, temporal_window=30, n_depths=4):\n#         super"
    },
    {
      "cell": 760,
      "variable": "temporal_window",
      "value": "30",
      "context": "el):\n#     def __init__(self, temporal_window=30, n_depths=4):\n#         super"
    },
    {
      "cell": 761,
      "variable": "temporal_window",
      "value": "30",
      "context": "el):\n#     def __init__(self, temporal_window=30, n_depths=4):\n#         super"
    },
    {
      "cell": 762,
      "variable": "temporal_window",
      "value": "30",
      "context": "el):\n#     def __init__(self, temporal_window=30, n_depths=4):\n#         super"
    },
    {
      "cell": 764,
      "variable": "temporal_window",
      "value": "30",
      "context": "el):\n#     def __init__(self, temporal_window=30, n_depths=4):\n#         super"
    },
    {
      "cell": 765,
      "variable": "temporal_window",
      "value": "30",
      "context": "el):\n#     def __init__(self, temporal_window=30, n_depths=4):\n#         super"
    },
    {
      "cell": 765,
      "variable": "kernel_size",
      "value": "3",
      "context": "   tf.keras.layers.Conv1D(32, kernel_size=3, padding='same', activation='"
    },
    {
      "cell": 766,
      "variable": "temporal_window",
      "value": "30",
      "context": "odel):\n    def __init__(self, temporal_window=30, n_depths=4):\n        super()"
    },
    {
      "cell": 767,
      "variable": "temporal_window",
      "value": "30",
      "context": "= ZeroCurtainModel(\n#         temporal_window=30, \n#         n_depths=n_depths"
    },
    {
      "cell": 768,
      "variable": "temporal_window",
      "value": "30",
      "context": "= ZeroCurtainModel(\n#         temporal_window=30, \n#         n_depths=n_depths"
    },
    {
      "cell": 796,
      "variable": "batch_size",
      "value": "16",
      "context": "e mini-batches manually\n#     batch_size = 16\n#     n_samples = len(x_train"
    },
    {
      "cell": 797,
      "variable": "batch_size",
      "value": "32",
      "context": " Training configuration\n#     batch_size = 32\n#     n_samples = len(x_train"
    },
    {
      "cell": 800,
      "variable": "batch_size",
      "value": "32",
      "context": " Training configuration\n#     batch_size = 32\n#     n_samples = len(x_train"
    },
    {
      "cell": 803,
      "variable": "batch_size",
      "value": "32",
      "context": " Training configuration\n#     batch_size = 32\n#     n_samples = len(x_train"
    },
    {
      "cell": 807,
      "variable": "batch_size",
      "value": "32",
      "context": " Training configuration\n#     batch_size = 32\n#     n_samples = len(x_train"
    },
    {
      "cell": 809,
      "variable": "step",
      "value": "16",
      "context": ".Int('conv1_filters', 16, 64, step=16)\n            x = tf.keras.lay"
    },
    {
      "cell": 809,
      "variable": "step",
      "value": "32",
      "context": ".Int('conv2_filters', 32, 96, step=32)\n                x = tf.keras"
    },
    {
      "cell": 809,
      "variable": "step",
      "value": "16",
      "context": "p.Int('lstm_filters', 16, 48, step=16)\n            kernel_size = hp"
    },
    {
      "cell": 809,
      "variable": "step",
      "value": "0.1",
      "context": "('recurrent_dropout', 0, 0.3, step=0.1) #for better generalizability"
    },
    {
      "cell": 809,
      "variable": "step",
      "value": "16",
      "context": "hp.Int('dense_units', 16, 64, step=16)\n            x = tf.keras.lay"
    },
    {
      "cell": 809,
      "variable": "step",
      "value": "0.1",
      "context": "oat('dropout_rate', 0.1, 0.3, step=0.1))(x)\n            \n           "
    },
    {
      "cell": 810,
      "variable": "batch_size",
      "value": "32",
      "context": "train, y_train, x_val, y_val, batch_size=32, epochs=10):\n    with tf.devi"
    },
    {
      "cell": 812,
      "variable": "batch_size",
      "value": "32",
      "context": "_val, y_val, \n                batch_size=32, \n                epochs=10\n "
    },
    {
      "cell": 812,
      "variable": "step",
      "value": "0",
      "context": "trial_auc)}, \n                step=0\n            )\n            \n  "
    },
    {
      "cell": 812,
      "variable": "batch_size",
      "value": "32",
      "context": "   x_val, y_val, \n            batch_size=32, \n            epochs=50  # Ex"
    },
    {
      "cell": 824,
      "variable": "batch_size",
      "value": "32",
      "context": "batch_size = 32\nn_batches = int(np.ceil(len(x"
    },
    {
      "cell": 825,
      "variable": "batch_size",
      "value": "32",
      "context": "with tf.device('/CPU:0'):\n    batch_size = 32\n    n_batches = int(np.ceil(l"
    },
    {
      "cell": 841,
      "variable": "fontsize",
      "value": "10",
      "context": "ed Zero Curtain Probability', fontsize=10)\n    \n    plt.suptitle('Regio"
    },
    {
      "cell": 841,
      "variable": "fontsize",
      "value": "16",
      "context": "tern Russian Sites)', y=1.05, fontsize=16)\n    plt.tight_layout()\n    \n"
    },
    {
      "cell": 845,
      "variable": "batch_size",
      "value": "32",
      "context": "odel.evaluate(x_test, y_test, batch_size=32, verbose=1)"
    },
    {
      "cell": 853,
      "variable": "batch_size",
      "value": "32",
      "context": ", x_val, y_val, spatial_info, batch_size=32, epochs=100):\n    \"\"\"Train th"
    }
  ],
  "sort_operations": [
    {
      "cell": 2,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "is=0, ignore_index=True)\n    df_merged = df_merged.sort_values('datetime').reset_index(drop=True)\n    df_merged.t"
    },
    {
      "cell": 3,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "amp('2023-01-01')]\n            combined = combined.sort_values('datetime').reset_index(drop=True)\n            com"
    },
    {
      "cell": 3,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "'] < '2025-01-01']\n        final_data = final_data.sort_values('datetime').reset_index(drop=True)\n        final_d"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "'%Y-%m-%d %H:%M:%S')\ntundrafielddb = tundrafielddb.sort_values('date').reset_index(drop=True)\n\ntundrafielddb.to_c"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ", 'alt', 'source']].replace(-999, np.nan).dropna().sort_values('datetime').reset_index(drop=True)\ntundrafielddb_a"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "', 'st', 'source']].replace(-999, np.nan).dropna().sort_values('datetime').reset_index(drop=True)\ntundrafielddb_s"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " tundrafielddb_smc[tundrafielddb_smc['smc'] < 100].sort_values('datetime').reset_index(drop=True)\ntundrafielddb_s"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "= pd.concat(alt_dfs + [tundrafielddb_alt], axis=0).sort_values('datetime').reset_index(drop=True)\ncombined_df['al"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ", 'latitude', 'longitude', 'thickness', 'source']].sort_values('datetime').reset_index(drop=True)\ncombined_df['th"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ude', 'longitude', 'source', 'year', 'thickness']].sort_values('datetime').reset_index(drop=True)\nexternal_alt = "
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "] >= 49) & (external_alt['thickness'] < 600000.0)].sort_values('datetime').reset_index(drop=True)\nexternal_alt['t"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "hickness', 'thickness_m', 'standardization_note']].sort_values('datetime').reset_index(drop=True)\nexternal_alt.to"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ", 'datetime', 'source']]\n            diagnostic_df.sort_values('discrepancy', ascending=False).to_csv('thickness_"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "repancies by source:\")\n        print(source_groups.sort_values('mean', ascending=False))\n\nstandardized_df['thickn"
    },
    {
      "cell": 4,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "repancies by source:\")\n        print(source_groups.sort_values('mean', ascending=False))\n\nstandardized_df['thickn"
    },
    {
      "cell": 5,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "e','latitude','longitude','source','temperature']].sort_values('datetime').reset_index(drop=True)\ntemp = temp[tem"
    },
    {
      "cell": 5,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "et_index(drop=True)\ntemp = temp[temp.latitude>=49].sort_values('datetime').reset_index(drop=True)\nprint(f'Minimum"
    },
    {
      "cell": 5,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " borehole_df[borehole_df.temperature.isna()!=True].sort_values('datetime').reset_index(drop=True)\nborehole_df = b"
    },
    {
      "cell": 5,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " len(group) >= 3:\n            sorted_group = group.sort_values('depth_m')\n            depths = sorted_group['dept"
    },
    {
      "cell": 5,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "_borehole_df\nvalid_borehole_df = valid_borehole_df.sort_values('datetime').reset_index(drop=True)\nvalid_borehole_"
    },
    {
      "cell": 5,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "isna().sum()\nvalid_borehole_df = valid_borehole_df.sort_values('datetime').reset_index(drop=True)\nvalid_borehole_"
    },
    {
      "cell": 5,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "mperature', 'temp_quality', 'measurement_method']].sort_values('datetime').reset_index(drop=True)\nvalid_borehole_"
    },
    {
      "cell": 5,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "pring', 3: 'Summer', 4: 'Fall'})\ngtnp_st = gtnp_st.sort_values('datetime').reset_index(drop=True)\ngtnp_st\ngtnp_st"
    },
    {
      "cell": 5,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " len(group) >= 2:\n            sorted_group = group.sort_values('depth_m')\n            is_winter = sorted_group['s"
    },
    {
      "cell": 5,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "uality'] == 'valid']\nvalid_gtnp_st = valid_gtnp_st.sort_values('datetime').reset_index(drop=True)\ngtnp_st = valid"
    },
    {
      "cell": 6,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ", 'datetime', 'source']]\n            diagnostic_df.sort_values('discrepancy', ascending=False).to_csv('thickness_"
    },
    {
      "cell": 6,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "essed_df = processed_df[processed_df.latitude>=49].sort_values('datetime').reset_index(drop=True)\nprocessed_df = "
    },
    {
      "cell": 6,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "'measurement_method']]\nprocessed_df = processed_df.sort_values('datetime').reset_index(drop=True)\nprocessed_df.to"
    },
    {
      "cell": 6,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "f.datetime,format='mixed')\ncleaned_df = cleaned_df.sort_values('datetime').reset_index(drop=True)\ncleaned_df.to_c"
    },
    {
      "cell": 7,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "hickness(newdf3)\nstandardized_df = standardized_df.sort_values('datetime').reset_index(drop=True)\nstandardized_df"
    },
    {
      "cell": 7,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "f.csv', index=False)\nstandardized_df.sample(10000).sort_values('datetime').reset_index(drop=True).to_csv('standar"
    },
    {
      "cell": 7,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "')\ndata = data[~data.thickness.isna()]\ndata = data.sort_values('datetime').reset_index(drop=True)\nalt = data\ndel "
    },
    {
      "cell": 7,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "\ndata = data[~data.temperature.isna()]\ndata = data.sort_values('datetime').reset_index(drop=True)\ntemp = data\ndel"
    },
    {
      "cell": 8,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ear):\n            continue\n        profile = group.sort_values('depth_m')\n        if len(profile) < 2:\n          "
    },
    {
      "cell": 8,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ed_valid_gtnp_borehole_st_df.csv')\nalt_df = alt_df.sort_values('datetime').reset_index(drop=True)\nalt_df = alt_df"
    },
    {
      "cell": 8,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ex(drop=True)\nalt_df = alt_df[alt_df.latitude>=49].sort_values('datetime').reset_index(drop=True)\n\ndef standardiz"
    },
    {
      "cell": 8,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ", 'datetime', 'source']]\n            diagnostic_df.sort_values('discrepancy', ascending=False).to_csv('thickness_"
    },
    {
      "cell": 8,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "repancies by source:\")\n        print(source_groups.sort_values('mean', ascending=False))\nstandardized_df.to_csv('"
    },
    {
      "cell": 9,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ",'latitude','longitude','depth_cm','temperature']].sort_values('datetime').reset_index(drop=True)\ndst2 = dst2[['s"
    },
    {
      "cell": 9,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ",'latitude','longitude','depth_cm','temperature']].sort_values('datetime').reset_index(drop=True)\nru_dst = pd.con"
    },
    {
      "cell": 9,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "t_index(drop=True)\nru_dst = pd.concat([dst1,dst2]).sort_values('datetime').reset_index(drop=True)\n\ndef add_depth_"
    },
    {
      "cell": 9,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "native sources.\")\n\nru_dst_updated = ru_dst_updated.sort_values('datetime').reset_index(drop=True)\nru_dst_updated "
    },
    {
      "cell": 9,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "itude>=30]\nru_dst = ru_dst_updated\nru_dst = ru_dst.sort_values('datetime').reset_index(drop=True)\nru_dst.to_csv('"
    },
    {
      "cell": 9,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " len(group) >= 2:\n            sorted_group = group.sort_values('soil_temp_depth')\n            is_winter = sorted_"
    },
    {
      "cell": 9,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ity_flag'] == 'valid']\nvalid_ru_dst = valid_ru_dst.sort_values('datetime').reset_index(drop=True)\nru_dst = valid_"
    },
    {
      "cell": 9,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "n(np.unique(pd.read_csv('ru_dst_final_022425.csv').sort_values('datetime').reset_index(drop=True).site_id))"
    },
    {
      "cell": 10,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "me(df[datetime_col], format='mixed')\n    return df.sort_values(datetime_col).reset_index(drop=True)\n\ndef assign_s"
    },
    {
      "cell": 10,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " len(group) >= 2:\n            sorted_group = group.sort_values(depth_col)\n            is_winter = sorted_group[se"
    },
    {
      "cell": 10,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "t_id == 1041), 'site_name'] = 'Ny-\u00c5lesund'\ngtnp_st.sort_values('datetime').reset_index(drop=True).to_csv('ZC_data"
    },
    {
      "cell": 10,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " len(group) >= 2:\n            sorted_group = group.sort_values('depth')\n            is_winter = sorted_group['sea"
    },
    {
      "cell": 11,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ned_df)\n    try:\n        combined_df = combined_df.sort_values(['datetime', 'latitude', 'longitude'])\n    except:"
    },
    {
      "cell": 11,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ned_df)\n    try:\n        combined_df = combined_df.sort_values(['datetime', 'latitude', 'longitude'])\n    except:"
    },
    {
      "cell": 12,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "reshold]\n    ismn = ismn[ismn['latitude'].notna()].sort_values('datetime').reset_index(drop=True)\n    ismn = ismn"
    },
    {
      "cell": 12,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "drop=True)\n    ismn = ismn[ismn.longitude.notna()].sort_values('datetime').reset_index(drop=True)\n    \n    month_"
    },
    {
      "cell": 12,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " source_counts = outliers.groupby('source').size().sort_values(ascending=False)\n        print(source_counts.head("
    },
    {
      "cell": 12,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "moist_depth', 'source']\n    \n    return ismn_clean.sort_values('datetime').reset_index(drop=True)\n\ndef merge_neon"
    },
    {
      "cell": 12,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "rged_df = merged_df[merged_df['latitude'].notna()].sort_values('datetime').reset_index(drop=True)\n    merged_df ="
    },
    {
      "cell": 12,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "merged_df = merged_df[merged_df.longitude.notna()].sort_values('datetime').reset_index(drop=True)\n    \n    month_"
    },
    {
      "cell": 12,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "    ], ignore_index=True)\n    \n    result = result.sort_values(['datetime', 'latitude', 'longitude', 'depth'])\n  "
    },
    {
      "cell": 12,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "mat='mixed')\n    new_combined_df = new_combined_df.sort_values('datetime').reset_index(drop=True)\n    \n    print("
    },
    {
      "cell": 12,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "12-31 00:00:00']\n    filtered_data = filtered_data.sort_values(['datetime', 'latitude', 'longitude'])\n    filtere"
    },
    {
      "cell": 14,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "t.year <= self.max_year)\n        ]\n        df = df.sort_values(['datetime', 'alt'])\n        df = df.drop_duplicat"
    },
    {
      "cell": 14,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ear)\n            ]\n            final_df = final_df.sort_values(['site_id', 'datetime'])\n            final_df = fi"
    },
    {
      "cell": 14,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ta = annual_means[annual_means['site_id'] == site].sort_values('year')\n        if len(site_data) < 5:\n           "
    },
    {
      "cell": 14,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "if not trend_df.empty:\n        trend_df = trend_df.sort_values('trend_cm_per_year', ascending=False)\n    return t"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ", 'datetime', 'source']]\n            diagnostic_df.sort_values('discrepancy', ascending=False).to_csv('thickness_"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ".datetime = pd.to_datetime(df1.datetime)\ndf1 = df1.sort_values('datetime').reset_index(drop=True)\ndf1.to_csv('R18"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ".datetime = pd.to_datetime(df2.datetime)\ndf2 = df2.sort_values('datetime').reset_index(drop=True)\ndf2.to_csv('R38"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ".datetime = pd.to_datetime(df3.datetime)\ndf3 = df3.sort_values('datetime').reset_index(drop=True)\ndf3.to_csv('R40"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ".datetime = pd.to_datetime(df4.datetime)\ndf4 = df4.sort_values('datetime').reset_index(drop=True)\ndf4.to_csv('R3_"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "_df.datetime,format='mixed')\n    temp_df = temp_df.sort_values('datetime').reset_index(drop=True)\n    df5_list.ap"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "p_df)\ndf5 = pd.concat(df5_list, ignore_index=True).sort_values('datetime').reset_index(drop=True)\ndf5.to_csv('R5_"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "to_datetime(df6.datetime,format='mixed')\ndf6 = df6.sort_values('datetime').reset_index(drop=True)\ndf6.to_csv('R6_"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "repancies by source:\")\n        print(source_groups.sort_values('mean', ascending=False))\n\nstandardized_df = stand"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ",format='mixed')\nstandardized_df = standardized_df.sort_values('datetime').reset_index(drop=True)\nmonth_list = [p"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "_df.datetime,format='mixed')\nmerged_df = merged_df.sort_values('datetime').reset_index(drop=True)\nmerged_df.to_cs"
    },
    {
      "cell": 15,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "_df], ignore_index=True)\ncombined_df = combined_df.sort_values('datetime').reset_index(drop=True)\nprint(f\"Combine"
    },
    {
      "cell": 16,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ta = df_validated[df_validated['site_id'] == site].sort_values('datetime')\n            if len(site_data) > 1:\n   "
    },
    {
      "cell": 16,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "f_alt = pd.DataFrame(alt_data)\n    df_alt = df_alt.sort_values('datetime').reset_index(drop=True)\n    df_alt.to_c"
    },
    {
      "cell": 16,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "datetime = pd.to_datetime(df.datetime)\n    df = df.sort_values('datetime').reset_index(drop=True)\n    df.to_csv('"
    },
    {
      "cell": 16,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "datetime = pd.to_datetime(df.datetime)\n    df = df.sort_values('datetime').reset_index(drop=True)\n    df.to_csv('"
    },
    {
      "cell": 16,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "datetime = pd.to_datetime(df.datetime)\n    df = df.sort_values('datetime').reset_index(drop=True)\n    df.to_csv('"
    },
    {
      "cell": 16,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ta = annual_means[annual_means['site_id'] == site].sort_values('year')\n        if len(site_data) < 5:\n           "
    },
    {
      "cell": 16,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "if not trend_df.empty:\n        trend_df = trend_df.sort_values('trend_cm_per_year', ascending=False)\n    return t"
    },
    {
      "cell": 16,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "atetime(alt_data.datetime)\n    alt_data = alt_data.sort_values('datetime').reset_index(drop=True)\n    output_path"
    },
    {
      "cell": 16,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "  site_counts = alt_data.groupby('site_id').size().sort_values(ascending=False)\n    for site, count in site_count"
    },
    {
      "cell": 17,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "columns=rename_dict)\n    final_merge = final_merge.sort_values([column_standards['datetime'], column_standards['s"
    },
    {
      "cell": 17,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "l_df = final_df[keep_cols]\n    final_df = final_df.sort_values(['datetime', 'site_id'])\n    final_df = final_df.d"
    },
    {
      "cell": 17,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "soil_moist_values\n    })\n    result_df = result_df.sort_values('datetime')\n    return result_df\n\ndef add_latlon_t"
    },
    {
      "cell": 17,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "<= self.max_year)]\n            final_df = final_df.sort_values(['site_id', 'datetime'])\n            final_df = fi"
    },
    {
      "cell": 18,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "['datetime'],format='mixec')\nmerged_df = merged_df.sort_values('datetime').reset_index(drop=True)\n\nmerged_df.to_f"
    },
    {
      "cell": 18,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "['datetime'],format='mixec')\nmerged_df = merged_df.sort_values('datetime').reset_index(drop=True)\n\nmerged_df.to_f"
    },
    {
      "cell": 19,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ne added\n# gtnp_st = pd.read_csv('ZC_df_data.csv').sort_values('datetime').reset_index(drop=True) #Just another f"
    },
    {
      "cell": 19,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "logical data)\n# ru_dst = pd.read_csv('ru_dst.csv').sort_values('datetime').reset_index(drop=True)\n\ntemp = merged_"
    },
    {
      "cell": 19,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " = pd.read_csv('external_alt_final_insitu_df.csv').sort_values('datetime').reset_index(drop=True) #CALM, ABoVE AL"
    },
    {
      "cell": 19,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "v('external_alt_final_insitu_df_standardized.csv').sort_values('datetime').reset_index(drop=True) #CALM, ABoVE AL"
    },
    {
      "cell": 19,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "read_csv('cleaned_df_final_gtnp_alt_insitu_df.csv'.sort_values('datetime').reset_index(drop=True) #GTNP ALT (Acti"
    },
    {
      "cell": 20,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "_df[merged_df.soil_temp_standardized.isna()!=True].sort_values('datetime').reset_index(drop=True)\n\ndef analyze_te"
    },
    {
      "cell": 21,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "merged_df.thickness_m_standardized.isna() != True].sort_values('datetime').reset_index(drop=True)\nprint(f\"Number "
    },
    {
      "cell": 22,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "[merged_df.soil_moist_standardized.isna() != True].sort_values('datetime').reset_index(drop=True)\nprint(f\"Number "
    },
    {
      "cell": 23,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "    (sensitivity_df['events_per_site'] >= 1)\n    ].sort_values('events', ascending=False).iloc[0]\n    return {\n  "
    },
    {
      "cell": 23,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "].mean(axis=1)\n    exemplar_sites = exemplar_sites.sort_values('total_score', ascending=False)\n    print(f\"\\nFoun"
    },
    {
      "cell": 32,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "\n    \n#     # Sort by time\n#     site_df = site_df.sort_values('datetime')\n    \n#     # Calculate time difference"
    },
    {
      "cell": 32,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ignore_index=True)\n#             site_df = site_df.sort_values('datetime')\n            \n#             # Clean up\n"
    },
    {
      "cell": 34,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ues)\n#     common_values = pd.Series(value_counts).sort_values(ascending=False).head(20)\n    \n#     print(\"\\nMost"
    },
    {
      "cell": 65,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "c[:,:-1].to_html()))\ndfi.export(data.sample(10000).sort_values('datetime').reset_index(drop=True).head(50), \"merg"
    },
    {
      "cell": 67,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "p(index=long_events_summary.index.values.tolist()).sort_values('datetime').reset_index(drop=True)"
    },
    {
      "cell": 69,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " 'soil_moist_depth', 'source', \\\n  'data_type']]\\\n.sort_values('datetime').reset_index(drop=True)\n#moisture_data["
    },
    {
      "cell": 69,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ata.year.astype(int)\nmoisture_data = moisture_data.sort_values('datetime').reset_index(drop=True)\nmoisture_data\n\n"
    },
    {
      "cell": 70,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ss_m', 'thickness_m_standardized', 'data_type']]\\\n.sort_values('datetime').reset_index(drop=True)\nalt_data['datet"
    },
    {
      "cell": 70,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "year=alt_data.year.astype(int)\nalt_data = alt_data.sort_values('datetime').reset_index(drop=True)\nalt_data\n\ndatet"
    },
    {
      "cell": 71,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "oil_temp_depth_zone',\\\n  'source', 'data_type']]\\\n.sort_values('datetime').reset_index(drop=True)\ntemp_data['date"
    },
    {
      "cell": 71,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "r=temp_data.year.astype(int)\ntemp_data = temp_data.sort_values('datetime').reset_index(drop=True)\ntemp_data\n\ndate"
    },
    {
      "cell": 77,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "an',\n    'temp_stability': 'mean'\n}).reset_index().sort_values('duration_hours', ascending=False)\n\n# Export excep"
    },
    {
      "cell": 79,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "season\nseason_counts = df['season'].value_counts().sort_values(ascending=False)\naxes[0, 0].bar(season_counts.inde"
    },
    {
      "cell": 79,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "counts = df['soil_temp_depth_zone'].value_counts().sort_values(ascending=False)\naxes[1, 1].bar(depth_counts.index"
    },
    {
      "cell": 81,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "h for logical ordering\ndepth_groups = depth_groups.sort_values('soil_temp_depth')\n\nplt.figure(figsize=(10, 8))\npl"
    },
    {
      "cell": 106,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "sof(\n#                                 filtered_df.sort_values('datetime_key'),\n#                                "
    },
    {
      "cell": 106,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "_key'),\n#                                 moist_df.sort_values('datetime_key')[['datetime_key', 'soil_moist_stand"
    },
    {
      "cell": 106,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "\n    \n#     # Sort by time\n#     site_df = site_df.sort_values('datetime')\n    \n#     # Calculate time difference"
    },
    {
      "cell": 106,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ignore_index=True)\n#             site_df = site_df.sort_values('datetime')\n            \n#             # Clean up\n"
    },
    {
      "cell": 106,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "\n#                                     filtered_df.sort_values('datetime_key'),\n#                                "
    },
    {
      "cell": 106,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "\n#                                     filtered_df.sort_values('datetime_key'),\n#                                "
    },
    {
      "cell": 107,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "sof(\n#                                 filtered_df.sort_values('datetime_key'),\n#                                "
    },
    {
      "cell": 107,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "_key'),\n#                                 moist_df.sort_values('datetime_key')[['datetime_key', 'soil_moist_stand"
    },
    {
      "cell": 107,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "\n    \n#     # Sort by time\n#     site_df = site_df.sort_values('datetime')\n    \n#     # Calculate time difference"
    },
    {
      "cell": 107,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ignore_index=True)\n#             site_df = site_df.sort_values('datetime')\n            \n#             # Clean up\n"
    },
    {
      "cell": 107,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "\n#                                     filtered_df.sort_values('datetime_key'),\n#                                "
    },
    {
      "cell": 107,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "                         filtered_df = filtered_df.sort_values('datetime')\n#                                 mois"
    },
    {
      "cell": 107,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "             moisture_depth_df = moisture_depth_df.sort_values('datetime')\n                                \n#    "
    },
    {
      "cell": 107,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "                         filtered_df = filtered_df.sort_values('datetime')\n#                                 mois"
    },
    {
      "cell": 107,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "             moisture_depth_df = moisture_depth_df.sort_values('datetime')\n                                \n#    "
    },
    {
      "cell": 108,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "n []\n    \n    # Sort by time\n    site_df = site_df.sort_values('datetime')\n    \n    # Calculate time differences\n"
    },
    {
      "cell": 133,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "enhanced_events = enhanced_events.sort_values('datetime_min').reset_index(drop=True)"
    },
    {
      "cell": 170,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ological order\n#             zone_data = zone_data.sort_values('year')\n            \n#             fig.add_trace(\n"
    },
    {
      "cell": 173,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "by total score\n    exemplar_sites = exemplar_sites.sort_values('total_score', ascending=False)\n    \n    # Print s"
    },
    {
      "cell": 173,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "by total score\n    exemplar_sites = exemplar_sites.sort_values('total_score', ascending=False)\n    \n    # Print s"
    },
    {
      "cell": 173,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "e(site_data['end_date'])\n    site_data = site_data.sort_values('start_date')\n    \n    # Get site location\n    sit"
    },
    {
      "cell": 195,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "set - group by site, depth, and time\n#     df = df.sort_values(['source', 'soil_temp_depth', 'datetime'])\n    \n# "
    },
    {
      "cell": 195,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "     # Extract time series\n#         group = group.sort_values('datetime')\n        \n#         # Check for gaps th"
    },
    {
      "cell": 195,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " # Re-sort by time\n#                 group = group.sort_values('datetime')\n        \n#         # Calculate tempera"
    },
    {
      "cell": 195,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " \n#         # Sort by time\n#         group = group.sort_values('datetime')\n        \n#         # Create feature se"
    },
    {
      "cell": 195,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " \n#         # Sort by time\n#         group = group.sort_values('datetime')\n        \n#         # Prepare features "
    },
    {
      "cell": 195,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": ":\n#         # Sort by time\n#         group = group.sort_values('datetime_min')\n        \n#         current_event ="
    },
    {
      "cell": 195,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ues)\n#     common_values = pd.Series(value_counts).sort_values(ascending=False).head(20)\n    \n#     print(\"\\nMost"
    },
    {
      "cell": 195,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " \n#     # Sort by datetime\n#     site_df = site_df.sort_values('datetime')\n    \n#     # Calculate temperature der"
    },
    {
      "cell": 197,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "      # Sort by time\n                group = group.sort_values('datetime')\n                \n                # Cre"
    },
    {
      "cell": 197,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "      # Sort by time\n                group = group.sort_values('datetime')\n                \n                # Pre"
    },
    {
      "cell": 197,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "tain_events['soil_temp_depth'] == depth)\n        ].sort_values('datetime_min')\n        \n        current_event = N"
    },
    {
      "cell": 221,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "    # Sort by time\n#                 group = group.sort_values('datetime')\n                \n#                 # C"
    },
    {
      "cell": 221,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "    # Sort by time\n#                 group = group.sort_values('datetime')\n                \n#                 # P"
    },
    {
      "cell": 221,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "in_events['soil_temp_depth'] == depth)\n#         ].sort_values('datetime_min')\n        \n#         current_event ="
    },
    {
      "cell": 236,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "      # Sort by time\n                group = group.sort_values('datetime')\n                \n                # Cre"
    },
    {
      "cell": 236,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "      # Sort by time\n                group = group.sort_values('datetime')\n                \n                # Pre"
    },
    {
      "cell": 236,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "tain_events['soil_temp_depth'] == depth)\n        ].sort_values('datetime_min')\n        \n        current_event = N"
    },
    {
      "cell": 326,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "    # Sort by time\n#                 group = group.sort_values('datetime')\n                \n#                 # C"
    },
    {
      "cell": 326,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "    # Sort by time\n#                 group = group.sort_values('datetime')\n                \n#                 # P"
    },
    {
      "cell": 326,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "in_events['soil_temp_depth'] == depth)\n#         ].sort_values('datetime_min')\n        \n#         current_event ="
    },
    {
      "cell": 373,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "comparison_df2 = comparison_df2.sort_values('start_time').reset_index(drop=True)"
    },
    {
      "cell": 407,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "comparison_df2 = comparison_df2.sort_values('start_time').reset_index(drop=True)"
    },
    {
      "cell": 422,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "rison, orient='index')\n        top_sites = site_df.sort_values(by=['physical_days', 'model_days'], ascending=Fals"
    },
    {
      "cell": 425,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "    # Sort by time\n#                 group = group.sort_values('datetime')\n                \n#                 # C"
    },
    {
      "cell": 425,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "    # Sort by time\n#                 group = group.sort_values('datetime')\n                \n#                 # P"
    },
    {
      "cell": 425,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "in_events['soil_temp_depth'] == depth)\n#         ].sort_values('datetime_min')\n        \n#         current_event ="
    },
    {
      "cell": 425,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "\n    \n#     # Sort by time\n#     site_df = site_df.sort_values('datetime')\n    \n#     # Calculate time difference"
    },
    {
      "cell": 425,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ignore_index=True)\n#             site_df = site_df.sort_values('datetime')\n            \n#             # Clean up\n"
    },
    {
      "cell": 425,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ues)\n#     common_values = pd.Series(value_counts).sort_values(ascending=False).head(20)\n    \n#     print(\"\\nMost"
    },
    {
      "cell": 425,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "son, orient='index')\n#         top_sites = site_df.sort_values(by=['physical_days', 'model_days'], ascending=Fals"
    },
    {
      "cell": 606,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "y importance\n        importance_df = importance_df.sort_values('Importance', ascending=False)\n        \n        lo"
    },
    {
      "cell": 606,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ances\n#     })\n#     importance_df = importance_df.sort_values('Importance', ascending=False)\n#     force_print(\""
    },
    {
      "cell": 606,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "portances\n    })\n    importance_df = importance_df.sort_values('Importance', ascending=False)\n    force_print(\"Fe"
    },
    {
      "cell": 606,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "importance\n#         importance_df = importance_df.sort_values('Importance', ascending=False)\n        \n#         "
    },
    {
      "cell": 606,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "ances\n#     })\n#     importance_df = importance_df.sort_values('Importance', ascending=False)\n#     force_print(\""
    },
    {
      "cell": 606,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "rt by importance\n    importance_df = importance_df.sort_values('Importance', ascending=False)\n    \n    # Plot fea"
    },
    {
      "cell": 622,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "y importance\n        importance_df = importance_df.sort_values('Importance', ascending=False)\n        \n        lo"
    },
    {
      "cell": 630,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "rt by importance\n    importance_df = importance_df.sort_values('Importance', ascending=False)\n    \n    if logger:"
    },
    {
      "cell": 646,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "      # Sort by time\n                group = group.sort_values('datetime')\n                \n                # Cre"
    },
    {
      "cell": 646,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "      # Sort by time\n                group = group.sort_values('datetime')\n                \n                # Pre"
    },
    {
      "cell": 646,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "tain_events['soil_temp_depth'] == depth)\n        ].sort_values('datetime_min')\n        \n        current_event = N"
    },
    {
      "cell": 661,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "year for animation\n    validated_df = validated_df.sort_values('year')\n    \n    # Get year range\n    min_year = v"
    },
    {
      "cell": 661,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "year for animation\n    validated_df = validated_df.sort_values('year')\n    \n    # Get unique years\n    years = va"
    },
    {
      "cell": 687,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "      # Sort and remove duplicates\n        df = df.sort_values(['datetime', 'latitude', 'longitude'])\n        df "
    },
    {
      "cell": 687,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "      # Sort and remove duplicates\n        df = df.sort_values(['datetime', 'latitude', 'longitude'])\n        df "
    },
    {
      "cell": 725,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": " by datetime and depth\n#             group = group.sort_values(['datetime', 'depth'])\n            \n#             "
    },
    {
      "cell": 726,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "s = depth_counts[depth_counts >= min_depths].index.sort_values()\n    \n#     # Filter for common depths\n#     temp"
    },
    {
      "cell": 858,
      "parameter": "sort_values",
      "match": ".sort_values(",
      "value": null,
      "context": "nt(filtered_df)\nfiltered_df[filtered_df.Band=='L'].sort_values('Line ID').reset_index(drop=True).drop(columns=['D"
    }
  ],
  "stratification": [
    {
      "cell": 106,
      "parameter": "stratify",
      "match": "stratify=",
      "value": null,
      "context": "         range(len(X)), test_size=0.2, \n#         stratify=X['spatial_group'], random_state=42\n#     )\n    \n#"
    },
    {
      "cell": 106,
      "parameter": "stratify",
      "match": "stratify=",
      "value": null,
      "context": "size=0.25,  # 25% of 80% = 20% of total\n#         stratify=X.iloc[train_val_idx]['spatial_group'], random_sta"
    },
    {
      "cell": 107,
      "parameter": "stratify",
      "match": "stratify=",
      "value": null,
      "context": "         range(len(X)), test_size=0.2, \n#         stratify=X['spatial_group'], random_state=42\n#     )\n    \n#"
    },
    {
      "cell": 107,
      "parameter": "stratify",
      "match": "stratify=",
      "value": null,
      "context": "size=0.25,  # 25% of 80% = 20% of total\n#         stratify=X.iloc[train_val_idx]['spatial_group'], random_sta"
    },
    {
      "cell": 195,
      "parameter": "stratify",
      "match": "stratify=",
      "value": null,
      "context": "_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n#     X_val, X_test, y_val, y_test = train_test"
    },
    {
      "cell": 195,
      "parameter": "stratify",
      "match": "stratify=",
      "value": null,
      "context": "t(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n    \n#     # Build model\n#     print(\"Buil"
    },
    {
      "cell": 630,
      "parameter": "stratify",
      "match": "stratify=",
      "value": null,
      "context": "\n                random_state=42,\n                stratify=y\n            )\n            \n            # Then sp"
    },
    {
      "cell": 630,
      "parameter": "stratify",
      "match": "stratify=",
      "value": null,
      "context": "\n                random_state=42,\n                stratify=y[train_val_indices]\n            )\n            \n  "
    }
  ]
}