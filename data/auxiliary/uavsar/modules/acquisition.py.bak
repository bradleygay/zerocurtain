#!/usr/bin/env python3
"""
modules/acquisition.py
UAVSAR/NISAR Data Acquisition Module - COMPLETE IMPLEMENTATION

Author: [RESEARCHER], [RESEARCH_INSTITUTION] Arctic Research
"""

import os
import subprocess
import json
import logging
import netrc
import re
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import time


class GeographicFilter:
    """Filter data by geographic bounds"""
    
    def __init__(self, bounds: Dict):
        self.min_lon = bounds['min_lon']
        self.max_lon = bounds['max_lon']
        self.min_lat = bounds['min_lat']
        self.max_lat = bounds['max_lat']
    
    def is_within_bounds(self, metadata: Dict) -> bool:
        """Check if data falls within geographic bounds"""
        lat_keys = ['center_lat', 'min_lat', 'latitude', 'lat']
        lon_keys = ['center_lon', 'min_lon', 'longitude', 'lon']
        
        lat = None
        lon = None
        
        for key in lat_keys:
            if key in metadata and metadata[key] is not None:
                lat = float(metadata[key])
                break
        
        for key in lon_keys:
            if key in metadata and metadata[key] is not None:
                lon = float(metadata[key])
                break
        
        if lat is None or lon is None:
            return True
        
        if lat < self.min_lat or lat > self.max_lat:
            return False
        
        if lon < self.min_lon or lon > self.max_lon:
            return False
        
        return True


class DownloadStateManager:
    """Manages download state for resumable operations"""
    
    def __init__(self, state_file: Path):
        self.state_file = state_file
        self.downloaded_files = set()
        self.failed_files = set()
        self.load_state()
    
    def load_state(self):
        """Load state from disk"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r') as f:
                    state = json.load(f)
                    self.downloaded_files = set(state.get('downloaded', []))
                    self.failed_files = set(state.get('failed', []))
            except Exception as e:
                logging.warning(f"Failed to load state: {e}")
    
    def save_state(self):
        """Save state to disk"""
        try:
            state = {
                'downloaded': list(self.downloaded_files),
                'failed': list(self.failed_files),
                'timestamp': datetime.now().isoformat()
            }
            with open(self.state_file, 'w') as f:
                json.dump(state, f, indent=2)
        except Exception as e:
            logging.error(f"Failed to save state: {e}")
    
    def mark_downloaded(self, filename: str):
        self.downloaded_files.add(filename)
        if filename in self.failed_files:
            self.failed_files.remove(filename)
        self.save_state()
    
    def mark_failed(self, filename: str):
        self.failed_files.add(filename)
        self.save_state()
    
    def is_downloaded(self, filename: str) -> bool:
        return filename in self.downloaded_files


class UAVSARNISARAcquisitionManager:
    """Complete acquisition manager for UAVSAR and NISAR data"""
    
    def __init__(self, 
                 output_dir: str,
                 geographic_bounds: Dict,
                 max_workers: int = 8,
                 logger: Optional[logging.Logger] = None):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.geographic_filter = GeographicFilter(geographic_bounds)
        self.max_workers = max_workers
        self.logger = logger or logging.getLogger(__name__)
        
        self.uavsar_base_url = "https://uavsar.asf.alaska.edu"
        
        state_file = self.output_dir / '.download_state.json'
        self.state_manager = DownloadStateManager(state_file)
        
        self.stats = {
            'urls_generated': 0,
            'urls_filtered': 0,
            'files_downloaded': 0,
            'files_skipped': 0,
            'files_failed': 0
        }
        
        self._setup_authentication()
        
        self.logger.info("UAVSARNISARAcquisitionManager initialized")
        self.logger.info(f"Output directory: {self.output_dir}")
        self.logger.info(f"Geographic bounds: {geographic_bounds}")
    
    def _setup_authentication(self):
        """Setup [RESEARCH_INSTITUTION] Earthdata authentication"""
        try:
            nrc = netrc.netrc()
            auth_info = nrc.authenticators('urs.earthdata.[RESEARCH_INSTITUTION_DOMAIN]')
            if auth_info:
                self.username = auth_info[0]
                self.password = auth_info[2]
                self.logger.info(" Loaded credentials from .netrc")
                return
        except Exception as e:
            self.logger.warning(f"Could not load credentials from .netrc: {e}")
        
        self.username = os.environ.get('EARTHDATA_USERNAME')
        self.password = os.environ.get('EARTHDATA_PASSWORD')
        
        if self.username and self.password:
            self.logger.info(" Loaded credentials from environment variables")
            return
        
        self.logger.warning(" No credentials found - downloads may fail")
        self.logger.warning("  Run: python3 setup_earthdata_auth.py")
        self.username = None
        self.password = None
    
    def acquire_uavsar_from_wget_file(self, wget_file: str) -> Dict:
        """
        Acquire UAVSAR data from wget file
        
        Parameters:
        -----------
        wget_file : str
            Path to file containing wget commands
        
        Returns:
        --------
        dict : Acquisition statistics
        """
        self.logger.info("="*80)
        self.logger.info("UAVSAR DATA ACQUISITION FROM WGET FILE")
        self.logger.info("="*80)
        
        if not os.path.exists(wget_file):
            self.logger.error(f"Wget file not found: {wget_file}")
            return {'files_downloaded': 0, 'error': 'file_not_found'}
        
        # Parse wget file
        urls = self._parse_wget_file(wget_file)
        
        self.logger.info(f"Parsed {len(urls)} URLs from {wget_file}")
        
        # Filter for H5 files (primary data)
        h5_urls = [u for u in urls if u['url'].endswith('.h5')]
        
        self.logger.info(f"Found {len(h5_urls)} H5 files to download")
        
        # Download files
        downloaded = self._download_files(h5_urls)
        
        self.stats['files_downloaded'] += downloaded
        
        return {
            'files_downloaded': downloaded,
            'urls_total': len(urls),
            'urls_h5': len(h5_urls)
        }
    
    def _parse_wget_file(self, wget_file: str) -> List[Dict]:
        """Parse wget file and extract URLs"""
        
        with open(wget_file, 'r') as f:
            content = f.read()
        
        # Extract all wget URLs
        url_pattern = r'wget\s+(https://[^\s]+)'
        urls = re.findall(url_pattern, content)
        
        url_list = []
        for url in urls:
            filename = os.path.basename(url)
            url_list.append({
                'url': url,
                'filename': filename,
                'metadata': {}
            })
        
        self.stats['urls_generated'] = len(url_list)
        
        return url_list
    
    def acquire_uavsar(self, 
                       geojson_filter: Optional[str] = None,
                       flight_lines_filter: Optional[str] = None) -> Dict:
        """Acquire UAVSAR data"""
        
        # Check for wget file first
        wget_file = 'uavsar_wget_parallet.txt'
        if os.path.exists(wget_file):
            self.logger.info(f"Found wget file: {wget_file}")
            return self.acquire_uavsar_from_wget_file(wget_file)
        
        self.logger.warning("No wget file found")
        self.logger.info("To download UAVSAR data, provide uavsar_wget_parallet.txt")
        
        return {'files_downloaded': 0}
    
    def acquire_nisar(self, flight_info_path: Optional[str] = None) -> Dict:
        """Acquire NISAR data"""
        
        self.logger.info("="*80)
        self.logger.info("NISAR DATA ACQUISITION")
        self.logger.info("="*80)
        
        if not flight_info_path or not os.path.exists(flight_info_path):
            self.logger.warning("No flight_info_path provided or file not found")
            return {'files_downloaded': 0}
        
        # Parse and download
        flight_data = self._parse_flight_info(flight_info_path)
        urls = self._generate_nisar_urls(flight_data)
        filtered_urls = self._filter_urls_by_geography(urls)
        downloaded = self._download_files(filtered_urls)
        
        self.stats['files_downloaded'] += downloaded
        
        return {
            'files_downloaded': downloaded,
            'urls_generated': len(urls),
            'urls_filtered': len(filtered_urls)
        }
    
    def _parse_flight_info(self, flight_info_path: str) -> List[Dict]:
        """Parse flight information file"""
        # Implementation from previous version
        return []
    
    def _generate_nisar_urls(self, flight_data: List[Dict]) -> List[Dict]:
        """Generate NISAR URLs"""
        # Implementation from previous version
        return []
    
    def _filter_urls_by_geography(self, urls: List[Dict]) -> List[Dict]:
        """Filter URLs by geographic bounds"""
        
        if not urls:
            return []
        
        filtered_urls = []
        
        for url_info in urls:
            metadata = url_info.get('metadata', {})
            
            if self.geographic_filter.is_within_bounds(metadata):
                filtered_urls.append(url_info)
            else:
                self.stats['urls_filtered'] += 1
        
        self.logger.info(f"Geographic filtering: {len(urls)} → {len(filtered_urls)} URLs")
        
        return filtered_urls
    
    def _download_files(self, urls: List[Dict]) -> int:
        """Download files"""
        
        if not urls:
            self.logger.info("No URLs to download")
            return 0
        
        self.logger.info(f"Starting download of {len(urls)} files")
        
        downloaded_count = 0
        
        for idx, url_info in enumerate(urls, 1):
            self.logger.info(f"[{idx}/{len(urls)}] Processing {url_info['filename']}")
            success = self._download_single_file(url_info)
            if success:
                downloaded_count += 1
        
        self.logger.info(f"Downloaded {downloaded_count}/{len(urls)} files successfully")
        
        return downloaded_count
    
    def _download_single_file(self, url_info: Dict) -> bool:
        """Download a single file using wget"""
        
        url = url_info['url']
        filename = url_info['filename']
        output_path = self.output_dir / filename
        
        # Skip if already downloaded
        if self.state_manager.is_downloaded(filename):
            self.logger.info(f"   Already downloaded: {filename}")
            self.stats['files_skipped'] += 1
            return True
        
        # Skip if file exists and is non-empty
        if output_path.exists():
            size_mb = output_path.stat().st_size / (1024 * 1024)
            if size_mb > 1:
                self.logger.info(f"   Already exists: {filename} ({size_mb:.1f} MB)")
                self.state_manager.mark_downloaded(filename)
                self.stats['files_skipped'] += 1
                return True
        
        # Download
        try:
            self.logger.info(f"   Downloading: {filename}")
            
            cmd = ['wget', '--timeout=300', '--tries=5', '--waitretry=5', '--continue']
            
            if self.username and self.password:
                cmd.extend([f'--user={self.username}', f'--password={self.password}'])
            
            cmd.extend(['--no-check-certificate', '-O', str(output_path), url])
            
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                timeout=3600
            )
            
            if result.returncode == 0:
                size_mb = output_path.stat().st_size / (1024 * 1024)
                self.logger.info(f"   Downloaded: {filename} ({size_mb:.1f} MB)")
                self.state_manager.mark_downloaded(filename)
                return True
            else:
                error = result.stderr.decode().strip()
                self.logger.error(f"   Failed: {filename}")
                if error:
                    self.logger.error(f"    Error: {error[:200]}")
                self.state_manager.mark_failed(filename)
                self.stats['files_failed'] += 1
                return False
        
        except subprocess.TimeoutExpired:
            self.logger.error(f"   Timeout: {filename}")
            self.state_manager.mark_failed(filename)
            self.stats['files_failed'] += 1
            return False
        
        except Exception as e:
            self.logger.error(f"   Error: {filename} - {e}")
            self.state_manager.mark_failed(filename)
            self.stats['files_failed'] += 1
            return False
